{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hws2002/Deep_Learning_with_Keras/blob/main/Chapter11/Chapter11_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq2_JaxijNjW",
        "outputId": "b61499d5-40d8-40c0-9522-f00888706d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb': No such file or directory\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  5069k      0  0:00:16  0:00:16 --:--:-- 9352k\n"
          ]
        }
      ],
      "source": [
        "!rm -r aclImdb\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2nLnNVer9Da"
      },
      "source": [
        "수동으로 구현한 train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fj4FTzzk3DQ",
        "outputId": "8925126f-e51d-4ef2-dce5-28dab2e30fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_path = os.path.join(\"aclImdb\")\n",
        "\n",
        "base_dir = 'aclImdb'\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test/'\n",
        "\n",
        "train_dataset = []\n",
        "val_dataset = [] # 20%만 떼어가자\n",
        "\n",
        "train_pos_path = os.path.join(base_path, train_dir, 'pos')\n",
        "train_neg_path = os.path.join(base_path, train_dir, 'neg')\n",
        "\n",
        "train_pos_listdir = os.listdir(train_pos_path)\n",
        "num_val_pos_data = int(0.2 * len(train_pos_listdir))\n",
        "train_neg_listdir = os.listdir(train_neg_path)\n",
        "num_val_neg_data = int(0.2 * len(train_neg_listdir))\n",
        "\n",
        "for filename in train_pos_listdir[:-num_val_pos_data]:\n",
        "  with open(os.path.join(train_pos_path,filename),'r') as f:\n",
        "    train_dataset.append(f.read())\n",
        "for filename in train_pos_listdir[-num_val_pos_data:]:\n",
        "  with open(os.path.join(train_pos_path,filename),'r') as f:\n",
        "    val_dataset.append(f.read())\n",
        "\n",
        "num_train_pos_data = len(train_dataset)\n",
        "\n",
        "for filename in train_neg_listdir[:-num_val_neg_data]:\n",
        "  with open(os.path.join(train_neg_path,filename),'r') as f:\n",
        "    train_dataset.append(f.read())\n",
        "\n",
        "for filename in train_neg_listdir[-num_val_neg_data:]:\n",
        "  with open(os.path.join(train_neg_path,filename),'r') as f:\n",
        "    val_dataset.append(f.read())\n",
        "num_train_neg_data = len(train_dataset) - num_train_pos_data\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lFDOpJdpzO_",
        "outputId": "6573133f-323e-49bc-affd-de50ae311e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Not the most successful television project John Cleese ever did, \"Strange Case\" has the feel of a first draft that was rushed into production before any revisions could be made. There are some silly ideas throughout and even a few clever ones, but the story as a whole unfortunately doesn\\'t add up to much.<br /><br />Arthur Lowe is a hoot, though, as Dr. Watson, bionic bits and all. \"Good Lord.\"', shape=(), dtype=string)\n",
            "tf.Tensor(b\"George Cukor directs a brooding and cynical classic. The distinctive Ronald Coleman is at his best in this piece of Noir about an actor who loses himself in his roles. The acclaimed Anthony John(Colman)has driven his wife Brita(Signe Hasso)away with his highly fueled temper and erratic behavior. But the two manage to continue working together to please their audiences. Things begin to change as John is becoming bored with his career; he reluctantly agrees to play Othello. He gets deep into character as a jealous and murderous man. He begins walking a thin line between illusion and reality and ends up confusing his role with his own life and eventually kills his mistress(Shelley Winters),but has no memory of the dastardly deed.<br /><br />Colman seems faultless in this role. Winters is very impressive as the young woman determined to get away from her squalid life. Also in the cast: Edmond O'Brien, Ray Collins, Joe Sawyer and Whit Bissell.\", shape=(), dtype=string)\n",
            "tf.Tensor(b\"I think this movie is absolutely beautiful. And I'm not referring only to the breathtaking scenery. It's about two unhappy English housewives who decide to rent an Italian castle to take a break from their not so happy home lives. In the end four women total rent the place together, all with different personalities and different reasons for being there. In this magically beautiful place they all find the peace they're longing for and interestingly that peace comes from inward reflections and resolutions, more so than without. I also find it wonderful because of the relationships that are developed out kindness and understanding. The acting is a joy to watch in itself. I especially love the characters of Lottie (Josie Lawrence) and Lady Caroline (Polly Walker).\", shape=(), dtype=string)\n",
            "tf.Tensor(b'There should be more movies about our Native Americans. I especially think that using actual real Native Americans, would be the the right thing. I know that this Archie Belaney, who was played by Pierce Brosnan he did an excellent job in portraying that character, since he was an Englishman. But my suggestion to Hollywood, is to put more American Indians into the roles, and never use anyone else. The Sioux Nation has been put on the back burner far too long. Their poverty is a disgrace to our country. It is my firm belief that our country should return the Black Hills to the Sioux. We ask Israel to return their lands to the Arabs, but we do not make any effort to do the same, we should be ashamed of ourselves. We must practice what we preach!', shape=(), dtype=string)\n",
            "tf.Tensor(b\"Adolf Hitler's maniacal desire to impose his will on the rest of the world is the subject of this second in a seven part series of films produced by the U.S. War Department as an instructional tool for new soldiers entering the Armed Forces during World War II. Hitler's plan was methodical and well conceived, starting with the conquest of Eastern Europe, expanding to the European heartland, then moving on to the 'World Island' consisting of Europe, Asia and Africa. His final move would be to reach across the oceans for the ultimate conquest of the Americas and the World.<br /><br />In 1935, Hitler ordered national conscription, as the rest of the country fell under his evil spell. Grade school children sang his praises, and young German boys received training and indoctrination in military camps. Marching unopposed into Austria in 1938, Hitler followed by annexing a strip of land bordering Germany and Czechoslovakia called Sudetenland. In 1939, Hitler took all of Czechoslovakia. Later in the year, the world was stunned to learn that Germany signed a non-aggression pact with it's mortal enemy Russia, a ploy to delay Hitler's military involvement on too many fronts. Immediately after, Germany invaded Poland, bringing Hitler's conquest right to Russia's doorstep. He would deal with her later.<br /><br />It was during this period that Britain still declined to oppose Hitler's thrust across Europe. Prime Minister Neville Chamberlain felt he procured a great victory for his country by accepting a treaty with Germany, his infamous declaration stating 'Peace in Our Time'. It didn't turn out that way.<br /><br />The most fascinating information to be learned in this installment, at least to me, was provided by a small snippet of footage from a German pro Hitler rally in the mid '30's. It was led by a German American taking his cue directly from the homeland. The venue - Madison Square Garden!\", shape=(), dtype=string)\n",
            "tf.Tensor(b\"I recently bought this movie with a bunch of other LaserDiscs from eBay. Usually, I am into war and action movies but occasionally I enjoy romantic comedies.<br /><br />If you are bored by today's special FX films and high gloss romantic comedies you should check out Shop Around the Corner on a quiet evening. What I like about the movie is that the characters have a lot of decency. There is nothing fake or pretentious about them. Take Mr. Matuschek for example: When he finds out that his wife is cheating on him with one of his own employees he tries to shot himself. Not just because of the humiliation but because he has been unjust to the character of Stewart. (OK, weired example.) <br /><br />Yes, the focus of the movie is narrow and the plot is predictable. Yet still, I liked it a lot. If you likes Notting Hill then you will like Shop around the corner. in fact, Hugh Grant reminds me a lot of Jimmy Stewart.\", shape=(), dtype=string)\n",
            "tf.Tensor(b\"Usually I don't really like Emma Roberts so much, but after watching Nancy Drew it kind of changed my mind. The actors in the movies made the whole thing exciting and funny. Most of the time when you watch a mystery movie you can solve it before the middle of the show, but in this movie it's like you are actually there. The clues have to all fit together until you can finally understand the whole crime. I am still amazed how she found it out. The whole movie was really clever and the people who watched it with me loved the movie too. The clothes were my favorite part of the movie, it was so cute. I don't think there will be another movie like this until the sequel comes out. I give it a nine because the popular girls didn't really seem to have the part just right, but they still make me laugh. It was a really great movie and a great mystery. I definitely recommend watching it.\", shape=(), dtype=string)\n",
            "tf.Tensor(b\"This movie is more Lupin then most, especially coming from Funimation. Other then the bad dub, it isn't bad.<br /><br />The first hour is a lot like the Comic (which is what all Lupin the 3rd stuff is based on). Lupin's trying to get a huge treasure. Fujiko's using Lupin's weakness to women to try to get something out of it. The last bit isn't that bad, he's with another women, but of course Fujiko's still him number one.<br /><br />A lot of the other Lupin movies are more Family with cuss words then Lupin. Any good Lupin fan I think will be pleasantly surprised (I know I was after hearing so many bad things about this movie). It might be a bit better without the little animations rolling during the credits (they make it a little mushy) but overall, it isn't a bad film. Good enough to be one of the few I'd watch again of the Lupin III movies.\", shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_dataset)\n",
        "\n",
        "for i , element in enumerate(train_dataset):\n",
        "  print(element)\n",
        "  if i>= 3:\n",
        "    break\n",
        "\n",
        "\n",
        "for i , element in enumerate(val_dataset):\n",
        "  print(element)\n",
        "  if i>= 3:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uV1j5JDpsKI"
      },
      "source": [
        "텍스트 파일에 대해 text_dataset_from_directory 유틸리티로 쉽고 빠르게 text dataset을 만들 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Tapzw8sEzS"
      },
      "source": [
        "먼저 훈련 텍스트 파일에서 20%를 새로운 디렉터리 aclImdb/val로 덜어 내고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2QqlXcoRpyr5"
      },
      "outputs": [],
      "source": [
        "import pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / 'val'\n",
        "train_dir = base_dir / 'train'\n",
        "\n",
        "for category in (\"neg\",\"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int( 0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname ,\n",
        "                val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ikcyXetKew"
      },
      "source": [
        "text_dataset_from_directory 유틸리티로 훈련, 검증, 테스트를 위한 3개의 Dataset 객체를 만들 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZcVehgItIdB",
        "outputId": "c8aab9e6-c59a-4396-871e-309b54b3d5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/val', batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test', batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52O-24nIuPdw",
        "outputId": "5539e037-5e23-4033-a6de-e1b230a93fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
            "array([b'this movie is a very relaxed, romantic-comedy, which is thoroughly enjoyable. Meg Ryan does a very good job as the genius niece of Albert Einstein, though she does believe in her own skills. Tim Robbins does an equally good job as the mechanic who falls in love with her when she comes into his shop with her fianc\\xc3\\xa9 after her car stuffs up. I loved Walter Matthau as the one and only Albert Einstein. This movie just has a very relaxing feel to it, while still keeping some sort of seriousness to it (if that is actually possible, it happens here).<br /><br />I personally found this movie extremely entertaining, especially the old scientists - i thought they were fab and hilarious! This movie seems to have been underestimated beyond comprehension. If you have a cheeky sense of humour, this is the movie for you!',\n",
            "       b\"Check out the film's website, more time was put into making that than in the writing of the script for this movie. It couldn't be more off in it's boasting. Original story? Original? They must have found the script tucked away between the old testament, or face legal repercussion for that bit of horn-tooting. High-end special effects? Come on, I could do better with an Atari 7600 and a jug of earwax. Stylish cinematography? Oh yes, the America's funniest home video look is still a classic. I'm sure they had little money available for this title, so of course the sf aren't really that good, or a bit bad now and then, or just plain hilarious, but it's the story that makes this film a waste of time and money. 4 stories rolled into one and all of them brainless bits of seen-befores and done-already's.\",\n",
            "       b'This movie was physically painful to sit through, maybe because (like many people my age, and younger) I grew up with Dr. Seuss and loved his books - funny, clever, whimsical and subversive at the same time. \"The Cat in the Hat\" sucks all of the interest and spark out of the story, and Mike Myer\\'s performance as the Cat is mostly bewildering. Why the Borscht Belt accent, the unfunny patter, the inappropriate jokes, the charmless costume? I had to go back and re-read the books to see the real problem: the books are SIMPLE. This movie is OVERBLOWN and way, way too long.<br /><br />You don\\'t expect every kids\\' movie to be Toy Story or The Iron Giant, but this one set a new low. How could Mike Myers need the money?',\n",
            "       b'Okay. So there aren\\'t really that many great movies around. Recent gems like American Dream, The Straight Story and even Toy Story 2 don\\'t normally come so close together. But boy (!) does this film counter-balance the quality.<br /><br />I have NO idea what these people thought they were doing. Are the financiers in this world so easily convinced to fund such a crock of ****? I can just see it now...<br /><br />Producer - \"So we\\'ve got Joe Fiennes. He\\'s cute as a button and was pretty good in Shakespeare in Love. And we\\'ve got Rhys Ifans, who isn\\'t cute but was cool in Notting Hill. We\\'ll mix in a really mediocre score, a few forgettable post-Britpop tunes, hemlock root and lizard brains and hey presto you\\'ve got the worst film of the new millennium.And believe me, it\\'s gonna be a hard job to make anything as bad as this in the next thousand years.\"<br /><br />The Bank - \"I like it! Any unnecessary sex? Bad camera movements? And what about the worst accents this side of Devil\\'s Own?\"<br /><br />Producer - \"Yeah, we got plenty of those.\"<br /><br />The Bank - \"Sounds great, where do we sign?\"<br /><br />Please.',\n",
            "       b\"I think I've seen all of the Grisham movies now and generally they're all very poor, except for The Rainmaker, but this one is so bad it's unbelievable<br /><br />WARNING SPOILERISH<br /><br />It's one of those movies where the character does the stupid irrational things that no one would ever do. He's a lawyer for Christ's sake. Why when his children go missing does he not call the Police. Oh yes it's because all the Police hate lawyers so they're just ignore him and let him be attacked.<br /><br />When he's arrested for murder they just let him go free, he would be locked up in a cell pending a bail hearing. <br /><br />Why would you drag your kids halfway across the country when you could easily protect them at home.<br /><br />The Police don't bother to try and find an escaped mental patient, they don't bother to interview his daughter.<br /><br />As for the ridiculous ending\\xc2\\x85.<br /><br />In summary, silly, very unrealistic and a complete waste of time.<br /><br />0/10 \\xc2\\x96 One of the worst films ever made.\",\n",
            "       b\"Obviously a film that has had great influence not only on the buddy genre but action genre as well. George Lucas had to be a fan of this flick as so much of his Star Wars series seems to a homage to Gunga Din. The characters that Grant, McLaglen, and Fairbanks play are just precursors of Han Solo, Luke Skywalker, and Chewbacca. Even Sam Jaffe's Gunga Din morphed into C-3PO and R2-D2 and like him or not: Jar Jar Binks.<br /><br />Today this film is viewed as non PC but there is a speech by Eduardo Ciannelli as Guru the leader of the Indian opposition to the British raj that could can be echoed in the sentiments of many today. <br /><br />To a young boy this was a great film. Three strong male leads and only a hint of romance. There was a time when young boys deemed kissing the girl in Saturday matinee film was just mush. Not like today when the more skin is greeted with delight. Too late to lament lost innocence.<br /><br />Hopefully this film will not be forgotten and a few who are channel surfing will stop at TCM and catch a film with action, adventure, and a cast of thousands instead of CGI actors.\",\n",
            "       b\"It seems like anybody can make a movie nowadays. It's like all you need is a camera, a group of people to be your cast and crew, a script, and a little money and walla you have a movie. Problem is that talent isn't always part of this equation and often times these kind of low budget films turn out to be duds. The video store shelves are filled with these so called films. These aren't even guilty pleasures, they're just a waste of celluloid that are better off forgotten. Troma Entertainment is known for making trash cinema, but most of their films are b movie gold. However, some of the films they've put out they had nothing to do with making and some, like 'Nightmare Weekend,' didn't deserve any form of release at all. <br /><br />Pros: The cast members do the best they can with the lousy material. Some unintentional hilarity. Moves at a good pace (Should at 81 minutes).<br /><br />Cons: Awful writing, which includes putrid dialogue and countless plot holes. Poorly lit, especially the night scenes and the ending, which you can't make out at all. Doesn't make a lick of sense. Badly scored. Cheap and very dated effects. Total lack of character development and you won't care about anybody. This is supposed to be a horror film, but it's lacking in that area and isn't the least bit scary. Nothing interesting or exciting happens. Loaded with unnecessary padding.<br /><br />Final thoughts: I never expected this to be some forgotten gem, but I never imagined it would be this bad. I don't know if it's the worst film ever made, but it's a definite contender. Troma should have let this film rot instead of giving it a release. Don't make the same mistake I did and let your curiosity get the best of you.<br /><br />My rating: 1/5\",\n",
            "       b\"Paul Hennessy and his wife, Cate must deal with their two teenage daughters and weird son...But after the untimely passing of John Ritter, the show became more about coping with the loss of a loved one...<br /><br />I found this show, passing through the channels one afternoon and I have to say I was laughing myself till my ribs ached, simply at the range of characters; the witty lines and the situation Paul would find himself dealing mostly with his daughters...From then on, I caught the rest of the show when I was free and I have to say the writing was very good..But then I read about John Ritter's death...Shortly afterwards I watched 'Goodbye' part 2 and I have to say I was nearly in tears, watching the emotions of the characters, losing a loved one...How Rory punches a wall in anger and frustration...How Cate deals with having to sleep in her bed all alone....Briget and Kerry talking about what they should have done.<br /><br />But the show does move on, bringing with it Jim Egan and CJ Barnes who provide great laughs, as Cate's father tries to protect his family and give 'man issue talks' to Rory...But the true gem is CJ...who is absolutely hilarious as the wild cousin.<br /><br />It will always be John Ritter's masterpiece.\",\n",
            "       b\"What a surprising treat to come across on late television. Had I only read a brief plot rundown on a television listing before seeing the movie, I would have passed. The idea of a movie about a hit-man-seeing-a shrink-wanting-to leave-the-business-and-falling-in-love....sounds trite. But the film works. From the start of the movie, it's clear the man carries a weight on his shoulders, before he even says a word. The look and feel of the film is perfect. dark, but not obnoxiously so.<br /><br />Aside from the hit-man family aspect which provides a touch of surrealism, Macy's character grapples with his marriage, and his father's control. Macy shows a repressed sadness, and his bedtime talks with his young son are amazing. The young boy shows acting skills well beyond his years, and the interaction between the father and son is so very natural, personal and loving.<br /><br />This is one of the best movies I've seen in a while, and I can't believe I came across it by accident on late night television.\",\n",
            "       b\"Casting Jack Cassidy as Ken Frankin was sheer brilliance. Cassidy personified arrogance, confidence, charm and wit - all with a condescending, evil little smirk on his face. In my opinion, Jack Cassidy is by far the best murderer (having appeared three times) in the Columbo series. This particular (and first) performance, is my favorite Columbo episode ever - hands down. A fresh faced Steven Spielberg did amazing camera work (yes, there were a couple of camera shadows on the actors at times)capturing the nuances and banter at different and intriguing angles between Columbo and Franklin. Also, the panoramic and tight in shots at Big Bear Lake, CA (Franklin's cabin home) were very impressive.<br /><br />If you have not yet seen this episode, then you owe it to yourself to do so - it's a true masterpiece.<br /><br />Jack Cassidy was a very talented actor and singer. His charismatic personality was highly infectious. His death in 1976, at age 49 was very sad and indeed very tragic - he surely had his best years ahead of him. Rest in Peace Jack, you will live on for eternity through your great work.\",\n",
            "       b\"This first installment of Crispin Glover's personal magnum opus asks you to think a little, and so can't be recommended for any viewer who doesn't want to sit and puzzle over Glover's imagery or follow the surprisingly simple\\xc2\\x97but weirdly obfuscated\\xc2\\x97thread of his narrative. To the more casual viewer, yes, it's probably going to come off as a confusing mish-mash of odd, startling, and disturbing imagery for imagery's sake. <br /><br />You get the sense that Glover doesn't mind that this is the case, and he'll almost as gladly listen to why someone hated the film as to why they enjoyed it. Glover's innate eagerness for and about his work and how audiences interpret it is strongly communicated not only through the film itself, but also through the unusual question and answer sessions that he frequently conducts following showings; he clearly hopes that people will continue to think about what he has presented.<br /><br />The easiest way to interpret and dismiss the film is to label it as Dada or nihilist, a juvenile attack on the modern movie industry from an actor who's worked both without and within. But there's a reason why Glover performs his slideshow before showing his movie, and it's not only to sell books; his books juxtapose and create a narrative from images and text that Glover pieced together, and What Is It? does similarly with imagery drawn from Western culture. <br /><br />What Is It? is an endearing and compelling film in ways one hardly expects while viewing. Much has already been made about Glover's use of actors with Down's syndrome, and indeed that is one of the most initially striking aspects of the film. So jarring, in fact, that many seem to interpret it as some sort of far-reaching crusade to see a more realistic and/or dignified portrayal of the disabled in movies and television\\xc2\\x97or, on the absolute other end of the spectrum, as a kind of direct exploitation of the disabled. But it's not either, and maybe that's part of what makes this film so uncomfortable for many: the underlying agenda is not a political one or one of hatred, but one of looking beyond the mainstream culture into a kind of outsider ugliness. It's not a film about Down's syndrome, but it is a film that is owned by the actors with Down's syndrome who appear in it.<br /><br />I'm the sort of person who is entirely gung-ho when it comes to ugliness and strangeness being portrayed so starkly that it is beautiful; happily for me, this is pretty much exactly how What Is It? presents itself to viewers. Glover uses the strange images of snails, death, and the disabled in part because he wants his audience to feel discomfort at either the sheer oddness of the imagery or the visceral reaction one has to the dying screams of an anthropomorphized snail. In some ways, the weirdly compelling (and occasionally downright grotesque) elements of What Is It? remind me of the work of the painter Francis Bacon\\xc2\\x85 he of the infamous popes, yes, and the odd distortions of the human figure that inevitably make viewers cringe and want to look away. Like Bacon's paintings, Glover's film manages to be opulent and humble, grainy and polished, chaotic and well-realized\\xc2\\x85 and the contradictions help to make it all the more disconcerting. But still this is not an entirely serious film, and it largely manages to sidestep the greatest pitfalls of pretension through the use of humor that, for the most part, derives from the use (and juxtaposition) of familiar items, images, and names of popular culture. And when What Is It? is funny, it is very funny.<br /><br />Overall, What Is It? is an impressive first film from Glover as a director and writer, and his presence as an actor in the film proves not to be nearly the distraction one might expect it to be. Watching it is like being an observer in the kind of dream that isn't exactly good or bad, but just strange\\xc2\\x85 and that leaves you feeling slightly grimy when you wake up. If that's the kind of art you enjoy, What Is It? is likely to exceed your expectations and be well-worth the effort of catching it in the theatre, along with The Big Slide Show and Glover himself. All in all, it's an experience you're unlikely to forget any time soon.\",\n",
            "       b'A surprising misfire from the usually reliable Larry Cohen (God Told Me Too, Q, etc.), Full Moon High tries so hard to be funny and fails miserably, even with decent turns by Ed McMahon(!) and Kenneth Mars. Alan Arkin looks embarrassed throughout his performance and son Adam simply looks numb. This makes Teen Wolf look like a comedy classic.',\n",
            "       b\"Fidois a very odd film. And in many ways, a very good one.<br /><br />My first thought after viewing, was how the hell are they going to market this thing? If Shaun of the Dead is a romantic comedy with zombies, Fido is a boy and his dog story blended with fifties nostalgia comedy with zombies. Doesn't exactly trip off the tongue.<br /><br />Fido has little of Shaun's carnage, gore & belly laughs. It is a different beast altogether (forgive the pun).<br /><br />Fido kicks off with a black & white information film that explains the back story - humans have won a war against zombies by developing a control collar that subdues the flesh-eaters into dumb servants.<br /><br />At first I thought we we were in for a fifties cold war paranoia parody a la Matin\\xc3\\xa9e, but we are soon hurled into a world of bright primary colours and fifties middle-class nostalgia.<br /><br />Young Timmy Robinon is a lonely kid who doesn't fit in at school. His mom is would-be social climber,and his dad is nervy and detached.<br /><br />Seeking to keep up with the Joneses, mom (Carry-Anne Moss) has acquired a zombie. Jimmy is disinterested at first, but 'Fido' (Billy Conelley) soon proves a great buddy for Jimmy. Until his collar goes on the blink...<br /><br />Fido is NOT a horror film, but my problem with the movie is figuring out exactly what it IS.<br /><br />Much of the humour is of the light family variety, and sometimes the plot line is too heavily reliant on the boy and his dog/family moments.<br /><br />Yet the film is shot through with wonderfully dark, truly funny moments, which while welcome, will ensure an R rating for what is, for extended periods, a family comedy.<br /><br />The film looks gorgeous, and is wonderfully performed by all involved.<br /><br />Despite its difficult tonal problems, I hope this movie finds a niche, as it's quite a little gem in this year's deluge of cinematic crap.\",\n",
            "       b\"Most horror movies are in fact horrible movies. They get to be same ol'-same ol'. Same ol' pack every minute with some cheap thrill (usually 'splatter') and nowadays they can pack every second with gaudy special effects. One of the goals of a really good horror flick is to suspend the sense of disbelief of the audience. For instance, I saw both of the recent Mummy movies and nearly got dizzy viewing ridiculous special effects every second. It probably costs a million dollars per second to make those movies and my sense of disbelief was never suspended, it grew roots.<br /><br />Subtlety can be more terrifying. Less is more. <br /><br />I first saw 'The Woman in Black' on the A&E channel. After flipping through the usual 987 channels of very bad television I stopped to watch it. This movie almost has the feel of a 'Masterpiece Theater' production. That was fine with me, I've always preferred British TV & movies anyway.<br /><br />Most viewers would find this to be too slowly paced. But the slow pacing helps give the story credibility. The special effects are few which lulls the viewer into thinking that this film is set in the real world thus making us a bit more uneasy. The makeup and costume for the ghost are kept simple and believable. Hollywood would have made her look like a she demon from hell with glowing eyes-fangs-claws etc. Hollywood would have done an overkill and turned this idea into a mediocrity.<br /><br />The woman only makes about five appearances in the film. Most of them are where she appears in the distance and even that creates a good fright. If she appeared too often, it could've cheapened the mood that gets set. However this movie is so well made that through much of the film we're led into sensing that she is there the whole time but not visible. The scene where she 'visits' Arthur Kidd late at night and we see her just a little too close is a masterpiece in horror.<br /><br />This is just an extraordinary film that I think should rate as one the finest horror films ever made. I have a copy of 'The Haunting', 'The Changling' and a zillion more. I haven't seen anything that tops 'The Woman in Black' yet although I'm still looking. This movie is so well made that it gives even the most hardened skeptic (like me) a moment where I almost had second thoughts about the non-existence of ghosts. I joke to people that I occasionally get brief fears that she could appear standing in the middle of the road or that I'd see her staring through my window, etc. Maybe she could be in a crowd at the mall glaring at me with her look of hate. This is how a really great horror film should be. Like a LaFanu novel, The Woman in Black very slowly pulls you in and wraps herself around your neck and before you realize it, she's squeezing the life out of you and then it's too late.<br /><br />Closest thing I have to a criticism is that this was made for the small screen... and it's a terrible shame that this is out of print. I just paid over $40 for my second copy of this movie. It's a major prize in my collection. Now I'm on a quest to find an even better horror movie that not only gives the chills but also qualifies a sound drama.\",\n",
            "       b'What an unfortunate mess is \"Shiner.\" I wanted to like this over-the-top, anti-film aspirant, and in fact found a number of moments with powerful resonance. Sadly, those moments are few and far between. While I appreciate some of what Calson was attempting, any advantage aspired to by bare bones, no budget cinematography was destroyed with some truly atrocious editing that benefited the movie not at all.<br /><br />While bad acting abounds in low budget (and big budget) cinema, Shiner has some remarkably bad performances that are nearly painful to watch. In particular the \"straight\" couple Linda and Young Guy. These are the two most poorly written characters offering almost nothing to the story. The acting is so abysmal and neither actor seems capable of resisting smirking or cracking up as they drearily drop their lines with an appalling lack of skill. The choppy editing almost lends the feeling that these roles were entirely gratuitous and dropped in to avoid the films being stereotypically cast as an oddball gay film. It would have been better off as such.<br /><br />With all that is going wrong for it, there are several performances that seem to capture what Calson was hoping to get. In particular the story centering on Bob and Tim. These are the two most richly drawn characters and offer the most rewards with genuinely captivating performances by Nicholas T. King (Bob) and David Zelinas (Tim). Tim is a boxer with some serious issues. Remarkably low self esteem is disguised by an almost cartoon like arrogance that he wears like armour plating. Obsessed with Tim, the seemingly harmless yet ultimately creepy Bob, stalks the boxer in classic cat-and-mouse fashion. When the tables are turned and hunter becomes the hunted, the resulting in the film\\'s only genuine emotional catharsis. In a film so artificially hard-edged (that\\'s a compliment) one character MUST have that revelatory break through (or breakdown, as the case proves here) and the final confrontation between Bob and Tim provide Zelinas and King opportunity to display some real acting chops.<br /><br />As played by Scott Stepp and Derris Nile, Tony and Danny seem to be the focus of the movie, and despite some bravado moments of their own (including one truly disturbing scene revealing the sex/violence obsession), but they can\\'t seem to escape a cartoon-like artifice and it\\'s difficult to look at - or beyond their seeming one note symphony and find anything other than the obvious.<br /><br />Ultimately this same raw material could (and should) be used to tell this story in better fashion. Alas, there really isn\\'t much to recommend this yet, the performances by Messrs. King and Zelinas, really do offer something special and a glimpse of what might have been and are ultimately worth seeing.',\n",
            "       b'Great CGI effects & a truly Oscar-worthy performance by Gary Sinise as Lt. Dan. <br /><br />Tom Hanks is a one-trick pony in this movie, how he got the Best Actor Oscar that year over Morgan Freeman was a crime. <br /><br />This movie is a pandering treacly love letter to the baby boom generation, with a barely concealed right-wing prejudice, beginning from Forrest\\'s service in Vietnam all the way through to the \"resolution\" with Jenny at the end.<br /><br />With that said, though, it is hugely entertaining and an American movie through and through. I found certain parts of this film exceedingly offensive, Zemeckis dumbs down this movie almost to the level of Gump himself . . .maybe that was the point he was trying to make.<br /><br />Watch this film and ask yourself \"What is Robert Zemeckis saying about what makes a good American?\" <br /><br />Forrest seems to have made the \"right\" choices and been at the \"right place at the right time\" for the last 45 years. Those who are wrong according to the director\\'s vision seem to pay a heavy price. So is Zemeckis saying that idiocy disguised as innocence and naivety is a patriotic, even AMERICAN quality?',\n",
            "       b'Joe Don Baker is...Thomas Jefferson Geronimo, a pudgy, sweaty murderous oaf in a stupid cowboy suit that Roy Rogers would have laughed at. Somehow he still has a badge, probably because he lives in Texas and they\\'ll let ANYTHING be law enforcement there.<br /><br />This greasy loser is a deputy sheriff near the Texas border. Not surprisingly, he was once a Texas Ranger but got kicked out because he seemed to think that the law was his own personal bouncing ball to be played with at his discretion. This includes shooting suspects who are over the international border into Mexico, beating up on suspects, cheating in gun fights, threatening women, starting gunfights that could have been avoided AND managing to get the life of a child threatened in the process, letting women he promised he would help and protect get killed just so that he could get out of jail, etc, etc. This guy makes L.A. cops look like saints in comparison.<br /><br />When his partner is killed by a pair of wandering Italian assassins, Joe Don\\'s character hunts them down and kills one of them. Then he takes the other to Italy at the behest of a Mr. Wilson, who rightly thinks that Joe Don will screw up big time. In record time, he loses the Italian and gets a Maltese cabby blown up in the process. This is just the first of the many deaths and major destruction that Joe Don leaves in a trail behind him as he rampages across Malta looking for Palermo(the Italian assassin).<br /><br />Thus begins the mobius strip part of the movie, in which our hero gets arrested, lectured by the Maltese chief of police, goes out and causes more trouble, gets arrested, gets lectured by the chief of police...and so on, and so on. Until you want to blow your brains out with Joe Don\\'s ivory handled pistol and be done with the horror.<br /><br />Joe Don proves his uselessness not just in the first time Palermo escapes, but in the subsequent boat chase in which he goes down in just one punch. Then he gets taken by Palermo after he threatens a woman with a coat hanger. You hope that Palermo will actually get to torture him in the basement cell he\\'s put in, but no-the stripper he threatened came and got him out, because he promised to protect her. Her throat promptly gets cut(big surprise) and Joe Don escapes into the night.<br /><br />And here you hope he might have been drowned in the (yet another) boat chase. But even the ocean doesn\\'t want him, and spits him up on a shore where he\\'s nursed by a poor Maltese family(what did they ever do to deserve that?) he returns to the city, where he\\'s arrested by the police, lectured by the police chief...arrrgghhh! The female police officer who\\'s been escorting him around frees him so that they can go get Palermo. Why she would do anything so brain dead as to destroy her career for this great slob is beyond me. It\\'s just head scratchily puzzling.<br /><br />They go out to the villa where Palermo is hiding, and start a shoot out. Joe Don blithely cheats, and kills Palermo. He then utters the great and dazzling last line of the movie: \"The big one has my badge. Can you go get it for me?\" Thank you for that immortal line, Mr. Baker. That will go down in the annals of movie history as the most literate, amazing, wondrous last line ever uttered by a character in a film. It certainly falls into line with everything else about the character. Bravo.',\n",
            "       b'Blood Castle (aka Scream of the Demon Lover, Altar of Blood, Ivanna--the best, but least exploitation cinema-sounding title, and so on) is a very traditional Gothic Romance film. That means that it has big, creepy castles, a headstrong young woman, a mysterious older man, hints of horror and the supernatural, and romance elements in the contemporary sense of that genre term. It also means that it is very deliberately paced, and that the film will work best for horror mavens who are big fans of understatement. If you love films like Robert Wise\\'s The Haunting (1963), but you also have a taste for late 1960s/early 1970s Spanish and Italian horror, you may love Blood Castle, as well.<br /><br />Baron Janos Dalmar (Carlos Quiney) lives in a large castle on the outskirts of a traditional, unspecified European village. The locals fear him because legend has it that whenever he beds a woman, she soon after ends up dead--the consensus is that he sets his ferocious dogs on them. This is quite a problem because the Baron has a very healthy appetite for women. At the beginning of the film, yet another woman has turned up dead and mutilated.<br /><br />Meanwhile, Dr. Ivanna Rakowsky (Erna Sch\\xc3\\xbcrer) has appeared in the center of the village, asking to be taken to Baron Dalmar\\'s castle. She\\'s an out-of-towner who has been hired by the Baron for her expertise in chemistry. Of course, no one wants to go near the castle. Finally, Ivanna finds a shady individual (who becomes even shadier) to take her. Once there, an odd woman who lives in the castle, Olga (Cristiana Galloni), rejects Ivanna and says that she shouldn\\'t be there since she\\'s a woman. Baron Dalmar vacillates over whether she should stay. She ends up staying, but somewhat reluctantly. The Baron has hired her to try to reverse the effects of severe burns, which the Baron\\'s brother, Igor, is suffering from.<br /><br />Unfortunately, the Baron\\'s brother appears to be just a lump of decomposing flesh in a vat of bizarre, blackish liquid. And furthermore, Ivanna is having bizarre, hallucinatory dreams. Just what is going on at the castle? Is the Baron responsible for the crimes? Is he insane? <br /><br />I wanted to like Blood Castle more than I did. As I mentioned, the film is very deliberate in its pacing, and most of it is very understated. I can go either way on material like that. I don\\'t care for The Haunting (yes, I\\'m in a very small minority there), but I\\'m a big fan of 1960s and 1970s European horror. One of my favorite directors is Mario Bava. I also love Dario Argento\\'s work from that period. But occasionally, Blood Castle moved a bit too slow for me at times. There are large chunks that amount to scenes of not very exciting talking alternated with scenes of Ivanna slowly walking the corridors of the castle.<br /><br />But the atmosphere of the film is decent. Director Jos\\xc3\\xa9 Luis Merino managed more than passable sets and locations, and they\\'re shot fairly well by Emanuele Di Cola. However, Blood Castle feels relatively low budget, and this is a Roger Corman-produced film, after all (which usually means a low-budget, though often surprisingly high quality \"quickie\"). So while there is a hint of the lushness of Bava\\'s colors and complex set decoration, everything is much more minimalist. Of course, it doesn\\'t help that the Retromedia print I watched looks like a 30-year old photograph that\\'s been left out in the sun too long. It appears \"washed out\", with compromised contrast.<br /><br />Still, Merino and Di Cola occasionally set up fantastic visuals. For example, a scene of Ivanna walking in a darkened hallway that\\'s shot from an exaggerated angle, and where an important plot element is revealed through shadows on a wall only. There are also a couple Ingmar Bergmanesque shots, where actors are exquisitely blocked to imply complex relationships, besides just being visually attractive and pulling your eye deep into the frame.<br /><br />The performances are fairly good, and the women--especially Sch\\xc3\\xbcrer--are very attractive. Merino exploits this fact by incorporating a decent amount of nudity. Sch\\xc3\\xbcrer went on to do a number of films that were as much soft corn porn as they were other genres, with English titles such as Sex Life in a Woman\\'s Prison (1974), Naked and Lustful (1974), Strip Nude for Your Killer (1975) and Erotic Exploits of a Sexy Seducer (1977). Blood Castle is much tamer, but in addition to the nudity, there are still mild scenes suggesting rape and bondage, and of course the scenes mixing sex and death.<br /><br />The primary attraction here, though, is probably the story, which is much a slow-burning romance as anything else. The horror elements, the mystery elements, and a somewhat unexpected twist near the end are bonuses, but in the end, Blood Castle is a love story, about a couple overcoming various difficulties and antagonisms (often with physical threats or harms) to be together.',\n",
            "       b\"this move was friggin hilarious!!! funniest I've seen in a while, akshay and john kick ass as always, and the chicks are hot too. the story is awesome, lots of great jokes, and whoever reviewed this before me is an idiot. to him i say that u are not of Indian background so u wouldn't understand the humor u moron. don't rate movies u don't understand. what did u watch, the subtitle version where majority of jokes are lost in translation? thats what i thought jackass. <br /><br />akshay kumar is the best actor ever and proves once again his versatility, he can do not only action but comedy as well, and is excellent at it. john has proved himself as well, this is his first comedy role and he was also excellent at it.\",\n",
            "       b'Bruce Almighty is the best Jim Carrey work since The Truman Show, and was a pleasant surprise after some of his recent \"Hey Hollywood - look how good I can act!\" box office disappointments. It\\'s great to see Jim recognizing and embracing his strengths. He won\\'t get an Academy Award but the film itself will last longer than many of the \"awarded films\" of the Academy. He is at the top of his form in this most recent film - it\\'s like the return of an old friend.<br /><br />Carrey, Freeman, and Aniston all do a great job together - comfortable in their comedy roles, superb comic timing, and obviously having fun together but without the \"hey mom - look how funny I am\" type of comedy. A real surprise was Steven Carrell as Carrey\\'s nemesis (Carrell of The Daily Show fame), who walked away with some the best and funniest scenes of the film. I laughed harder at Carell than anyone else in the past three years.<br /><br />I can foresee the religious nuts in the US will be up-in-arms over the treatment of God, but the bottom line of the film is true to all major theological beliefs - we are masses of protoplasms trying to get through our short lives by exercising our free will. Without Married With Children t o complain about, this will likely become a target of people with misplaced priorities (who know the types - men adorned in gold watches on Sunday morning and late nigh television, selling prayers to God). And, again, about 0.5% of the country will care and 80% of the media will report it.<br /><br />The bottom line: this a purely entertaining film, each audience member laughingly wondering what they would do, and a feel-good feeling at the movie conclusion. A walk down any major street in America has to confirm that God has a tremendous sense of humor. What better comic genius to remind us of that than Jim Carry.<br /><br />Thanks again, Jim -- it\\'s GREAT to have you back!!',\n",
            "       b'This movie had to be the worst horror movie I have ever seen. The acting was terrible, Horrible and cheesy and talk about a predictable plot! I will never watch this movie again nor will I recommend this movie to anyone. What a waste of time! First, as soon as the movie began I realized what I got myself into. All they did for this movie was copy scenes from many other horror movies out there and bunched them all into this one movie. The prank phone calls, halloween night, a psycho, and one knife! Its absolutely ridiculous. I was not scared at all during the movie, which I thought horror movies were supposed to do. As for the making of the movie, its pretty hilarious how they all talk about how this movie was so great and so scary. I mean how do you not realize that the movies is a cheap rip off of \"Scary Movie\" for example. At least get some good actors in there and then maybe it would have been pulled off as a good horror movie.',\n",
            "       b'Bell, Book and Candle was one of the great pop culture phenomena of the mid-twentieth century, very similar to the phenoms we see today (back in the 70\\'s - more than ten years later - there were still endless references to this film). It made Novak a huge star, put a nice item on Jack Lemon\\'s resume, cast new light on Jimmy Stewart, and gave Lancaster and Gingold new avenues to explore in their careers (both went on to continue to play witches and other curious \"old bats\", in film and television).<br /><br />Along with the 40s movie I Married a Witch (which helped to make Veronica Lake an icon), Bell, Book and Candle inspired the grand film and TV fascination with all things witchy that began with Bewitched and has continued through Practical Magic, Worst Witch and Harry Potter.<br /><br />What I rarely see noted is that the movie is also a rather interesting alternative Xmas movie. The story takes place over the Christmas holidays, and, despite the fact that it is superficially about witchcraft, actually embodies a great deal of Xmas spirit (giving, love, family, self-sacrifice, etc).<br /><br />I will always watch this movie (have seen it several times since my first viewing in the early 90\\'s) particularly if it is shown around or just after the holiday season. It has style, substance, a great cast, and terrific production values. And like Adam\\'s Rib, it casually expresses ideas that were rather radical for its time, are radical even now (in both movies the female character is guileless and powerful), and so always seems ahead of the times.',\n",
            "       b'A surprisingly complex and well crafted study of \"The First\" serial killer in the USSR. Set in the days of perestroika this intense piece is brought to full life with the performances of Stephen Reah and Donald Sutherland.<br /><br />This examination of Cicatillo as a killer is well rounded and by hinting at some of his behaviors while out right showing others there is a subtlety that is compelling without being overtly graphic. Not for the weak of heart however as it\\'s subject matter is often disturbing but necessary to it\\'s full development of the main participants in this fact based story.<br /><br />HBO has furnished us with an excellent film in an unusual manner. Congrats to the director and editor of this great piece. It is in my Top 10 Must see list.',\n",
            "       b\"I have been meaning to see this flick for the past few months. I was actually surprised at how good it was.<br /><br />The plot revolves around a group of high school teenagers who are bullying a boy named Marty. They constantly bully him until one of them makes a horrific mistake which leaves Marty horribly burned.<br /><br />A few years later, the group of reckless teenagers are invited back to their own high school which is now abandoned for a party. Though, not one of the reckless teenagers has organized this party.<br /><br />Later through the film, the teenagers start dying in the most gruesome of ways possible. I can certainly tell you that they are gory as well.<br /><br />At the end of the film, you find out it was all a dream and none of it happened. But, Marty is in the hospital with severe burns. Although the murders didn't happen, the burns and the pranks apparently did happen.<br /><br />The acting is terrible but that is fine.<br /><br />I love the story. I really sympathize with Marty. It's like Tamara (2005). The bullies get what's coming to them in the end and you end up feeling satisfied for the victim getting their sweet revenge.<br /><br />I would strongly recommend anyone pick this up if you are looking for 80s slashers.<br /><br />I give this movie 8 stars out of 10. Good cheesy slasher!\",\n",
            "       b'Note to previous reviewer: This movie is \"science-fiction adaptation of the Iliad\" according to the screenwriter. So whether the references are painful or not, no apologies, it is the basis for the film. They admit they stole...though adapted is the P.C. term.<br /><br />Great flick but too short. Probably didn\\'t come out as well as the author, director, or studio wanted, but pretty damn fun. The fact that the studio itself imploded during the making only helps add to its legacy.<br /><br />A big-budget remake wouldn\\'t be as fun, and probably wouldn\\'t do the screenplay any more justice. But it\\'s fun to dream about the potential there. A DVD release with some meager extras is apparently available but I don\\'t think it would play on NTSC players. I\\'m no expert and thus still trying to figure this out. For now, I live with the VHS incarnation.',\n",
            "       b'Your average garden variety psychotic nutcase (deliciously essayed with unhinged glee by Stephen Sachs) knocks off various dim-witted young \"adults\" (to use the term very loosely) in Dayton Hall University, which is being closed down for demolition. Featuring dreadful acting by the entire cast (Daphne Zuniga makes her ignominious and inauspicious film debut here as Debbie, a bimbo who has her head crushed by a car!), a hefty corpse tally of 10, okay make-up f/x by Matthew Mungle, a few bloody murders (baseball bat bludgeoning, chicken wire strangulation, your standard drill through the head bit, that sort of gruesome thing), a downbeat surprise twist ending which was later copied in \"Intruder,\" a creepy score by Christopher (\"Hellraiser\") Young, a slight smidgen of gratuitous female nudity, and endearingly incompetent direction by Jeffrey Obrow and Steve Carpenter (who also blessed us with \"The Power\" and \"The Kindred\"), this entertainingly abysmal slice\\'n\\'dice atrocity sizes up as a good deal of delectably dopey and drecky low-grade fun.',\n",
            "       b\"In the voice over which begins the film, Hughie(Billy Connolly), a roadie for the great 70's band Strange Fruit, said the reason lightning struck at a rock festival to stop Strange Fruit's set was that God was sick of 70's excess. Indeed, it's been popular to put down that era of music, and see punk as a welcome antidote to it. While I agree the excess was tiresome(as well as the misogynistic urges which came out of it), and like punk, I still am a fan of what is considered classic rock or glam rock, and this film about Strange Fruit's long, strange reunion is an affectionate tribute to those days.<br /><br />One of the reasons the film works is the care of the people behind the scenes. Brian Gibson directed WHAT'S LOVE GOT TO DO WITH IT, about Tina Turner(while I had problems with the dramatic parts of the film, the music was handled very well), writers Dick Clement and Ian Le Frenais co-wrote THE COMMITMENTS and were behind the music-oriented British TV show OVER THE RAINBOW, and the songs Strange Fruit played were co-written by Foreigner's Mick Jones(not to be confused with The Clash's Mick Jones), so it was a meeting of people who knew what they were talking about. Also, two cast members are musicians in their own right(Bill Nye I don't know about, though the film credits him with his own singing, and he certainly looks like a lead singer of that era, while Jimmy Nail was in another British TV show which was music-oriented, though I forget the name, and he was in EVITA), and the others are convincing at it. And while, as I said, a lot of 70's bands like Strange Fruit behaved badly towards women, the movie doesn't make the same mistake(except for the woman who follows Timothy Spall around); as the manager of the reunion, Juliet Aubrey is quite good and plays a fully rounded character.<br /><br />The other actors are all good as well, with special praise to Stephen Rea, who handles the more dramatic role well without sentimentality. There are a couple of plot points which don't work, but overall this is quite enjoyable. Oh yeah, and the music is good too.\",\n",
            "       b\"I had fun watching Red Eye. It's not a masterpiece, but it's well directed and structured. Cillian Murphy and Rachel McAdams are perfect in the role. Yes, it's the same old story with a different setting but Wes Craven gave it a good pace. At least not another Scream with the usual college killer. It's nice when you can see a clean, coherent thriller even when originality doesn't stand out as its main character. Particularly from a film-maker like Craven that has brought so many innovative ideas to the thriller and horror genre in the past and that now just lends himself to bringing home what could have been a good TV movie had it not been released theatrically. Good job!\",\n",
            "       b'Last year we were treated to two movies about Truman Capote writing the book from which this film was made - Capote and Infamous.<br /><br />I cannot imagine a movie like this being made in 1967. A stark, powerful and chillingly brutal drama; elevated to the status of a film classic by the masterful direction of Richard Brooks (Elmer Gantry, Cat on a Hot Tin Roof, The professional, Blackboard Jungle).<br /><br />It is interesting that Robert Blake, who starred in this film, has had so many problems of late that may be related to his portrayal of a killer in this film.<br /><br />This is a film that stays with you after viewing.',\n",
            "       b'I generally love these 1930 mystery/police Charlie Chan type of movies, and this is no exception. However, something seems bad with this movie. A late attempt to switch from cerebral Moto movies centered around the plot contrivances to a salad bar spoilt by comedy relief that is as relieving as sore feet. A typecast buffoon appears from nowhere impersonating a clumsy Englishman who plays the detective, and even other characters seem entangled into providing comedy relief. The plot may seem odd or a bare excuse to us today, but back then the possibility of epochal archaeological discoveries was not only real, but a commonplace occurrence.',\n",
            "       b'I had never heard of Robert Roy MacGregor before \"Rob Roy\" came out, but the movie is definitely worth seeing. Playing the title character, Liam Neeson brings the same spirit to the role that he brought to Oskar Schindler, and Jessica Lange also does a really good job as his wife Mary. Archibald Cunningham (Tim Roth) is one person very likely to make your skin crawl.<br /><br />All in all, this comes out as good as \"Braveheart\" (maybe even better). I laugh when I think of how Hollywood released two movies almost back-to-back taking a swipe at England. Very good. Also starring John Hurt, Eric Stoltz, Brian Cox and Jason Flemyng.',\n",
            "       b'Okay, so there is a front view of a Checker taxi, probably late 1930s model. It has the great triangular shaped headlights. There also is a DeSoto cab in this black and white, character driven, almost a musical love gone wrong story.<br /><br />The real pleasure here is the look at 1940s room interiors and fashions and hotel elevators. The hair styles, male and female are gorgeous. If Dolly Parton had Victor Mature\\'s hair she could have made it big. There is an artist loft that would be the envy of every Andy Warhol wannabe.<br /><br />If you watch this expecting a great Casablanca storyline or Sound of Music oom-pah-pah, you will be disappointed. There is a nice little story beneath the runway model approach in this film.<br /><br />My copy on DVD with another movie for $1 was very viewable. The title sequence was cute but not up there with Mad, Mad, Mad, Mad World or The Pink Panther. This was an RKO movie but it did not have the nice airplane logo that RKO used to use.<br /><br />I liked Victor Mature in One Million, B.C., and Sampson and Delilah and especially in Violent Saturday. See if you can find that one. He was wonderful in the comedy with Peter Sellers called Caccia Alla Volpe or After The Fox.<br /><br />Richard Carlson went on to do I Led Three Lives on TV in the early 1950s.<br /><br />Vic Mature was offered the part of Sampson\\'s father in the remake of Sampson and Delilah. He supposedly was asked if he would have any problems playing the part of the father since he was so well known as Sampson. Victor replied, \"If the money is right, I\\'ll play Sampson\\'s mother.\" <br /><br />Tom Willett'],\n",
            "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
            "array([b\"If you like bad movies, this is the one to see. It's incredibly low-budget special effects (you'll see what I mean) and use of non-actors was what gave this film it's charm. If you're bored with a group of friends, I highly recommend renting this B movie gem. It's mulletrific!\",\n",
            "       b'Since this picture is classified a \"pure entertainment\" work and since there are already many comments on it, I\\'d like hereby to address something relevant to the abuse of humour. We can see that Marlon Wayans is playing the joker role in this film. Certainly as long as he has been involved in the casting job, he has always been acting as a little man-an actor can change his customary dress but can hardly change his physical appearance-and the latter one can be an advantage when necessary. However far away from what I expected, I saw an image very disguising, pretending to expose different aspects of the baby life by mistake of a forty-year- old criminal. And with a ridiculous happy ending. So what is the point? Many elements are mixed up, some principal ones are violence, sex and criminal activities, amongst which the story is badly composed and to some extent, lack common sense: where is Vanessa when the peace of her house is violated and her husband\\'s life being pursued? In addition the diamond is even bigger than the world\\'s No.1 Cullinan! But the most sickening facet is the continuous attempt to make up the little man as a superman by showing his physical weak points. And they call it humour. A diamond is precious, hard and fragile; it cannot be cut by any other material but only be conquered by the hot blood of a male goat. Hence it\\'s no more a diamond but pieces of debris.',\n",
            "       b'I Last night I had the pleasure of seeing the movie BUG at the Florida Film Festival and let me say it was a real treat. The Directors were there and they did a Q&A afterwards. The movie begins with a young boy smashing a roach beneath his foot, a man who is nearby parking his car sees the young boy smash it and runs to ask the kid `why? why? did he have to kill that living creature?\\' in his rush to counsel the youth in the error of his ways, the man neglects to pay his parking meter, which starts off a whole chain of events involving people not at all related to him, some funny, some sad, and some ridiculous. This movie has a lot of laughs, Lots! and there are many actors which you will recognize. The main actors who stood out in the film for me were: Jamie Kennedy (from his comedy show the Jamie Kennedy Experiment, playing a fortune cookie writer; John Carroll Lynch (who plays Drew\\'s cross dressing brother on the Drew Carey show) playing the animal loving guy who just can\\'t get it right; Brian Cox (The original Hannibal Lecter in Manhunter) playing the germaphobic owner of a Donut and Chinese Food Take Out joint. There is one line where Cox tells his chef to wash off some pigs blood that is on the sidewalk by saying \"clean up that death\" which is quite funny mostly because of Cox\\'s \"obsessed with germs\" delivery. The funniest moment in the movie comes when a young boy imitates his father, whom he heard earlier in the day yell out `MotherF*****\\', while in the classroom. Another extremely funny and surreal scene is when Trudie Styler (Mrs. Sting herself) and another actor perform a scene on a cable access show, from the film the boy in the plastic bubble. The actor who hosts the cable access show is just amazing he is so serious and deadpan and his performance as both the doctor and the boy in the plastic bubble is enthralling. There are many other fine and funny actors and actresses in this film and having shot it in less than a month with a budget of just about $1 million, the directors Phil Hay and Matt Manfredi (who are screenwriters by trade, having written crazy/beautiful and the upcoming Tuxedo starring Jackie Chan) have achieved a film that is great, funny and endearing.',\n",
            "       b\"I had to stop watching this film (a pseudo-intellectual product for pretentious film viewers) twenty minutes into it because it was mediocre and dull enough to inspire yawns, not to mention that I was soon near tears over the $3.99 I had wasted at Blockbuster. Joanna Pacula's acting and her awfully rendered Slavic accent are sufficiently terrible to set one to gritting one's teeth. I knew that two hours of her would be two hours too many. Both Breuer and Nietzsche are played by unremarkable actors of strikingly few talents. While we're on the topic of talent, Breuer's supercilious assistant appears to have been pulled out of a local acting troupe. She clearly has not learned her craft. In fact, she's really quite awful. All the public scenes looked staged, with the extras walking mechanically about in their Sunday best. Turning this film off was far more satisfying than turning it on. Don't rent this terrible movie. You will be sorry you spent your money.\",\n",
            "       b\"Five minutes into this movie you realize that you have seen it all before. It is BOILER ROOM. It is THE FIRM. And it is THE DEVILS ADVOCATE. And there are NO new elements here. Except for the all-to-clear Bill Gates-allegory. Conpsiracies are always good stuff for movie-making, but why does it have to be so extreme ? Boiler room is a good movie, because it - for a while at least - seems realistic. In Antitrust everything is wrong. How realistic is it for example that your boss pay an impostor to be your girlfriend in order to make you work harder and control you ? I'd give it 1, but the soundtrack is OK, so 2/10.\",\n",
            "       b\"this film really tries to hard. if your going to make a horror film, at least give it a reason to believe in to hook the viewer. <br /><br />you wait and wait through the film expecting for some grand explanation but it doesn't. instead it tries to be too clever ending and not revealing anything. <br /><br />what was the point of the movie ? where it's actually going ? and more importantly what the hell was going on . . . <br /><br />why were they there and how does it tie into anything? just another weak sci-fi horror. i love the fake reviews on IMDb saying how great it is by related press releases to bump the movie (either that or people have low horizons). it's not worth your 2hrs at all.<br /><br />i'm not saying the film is better than the fragile, but at least that gave you reasoning and why things happened and has an end result. this doesn't and it just waffle's on with tons of padding to make everything feel scary. this film is about as low as when a stranger calls. god that was lame too. <br /><br />big tip, if your gonna make a horror, make it believable with reasoning and explain to the viewer what's going on, so they have a hook into your story. because if there's no reasoning or believability then there's no firm hold on anything and it can't be scary. no disrespect to the cast or crew cause they did a good job. it's just the poor writing.\",\n",
            "       b'Tell the truth I\\xe2\\x80\\x99m a bit stun to see all these positive review by so many people, which is also the main reason why I actually decide to see this movie. And after having seen it, I was really a disappointed, and this comes from the guy that loves this genre of movie.<br /><br />I\\xe2\\x80\\x99m surprise at this movie all completely \\xe2\\x80\\x93 it is like a kid\\xe2\\x80\\x99s movie with nudity for absolutely no reason and it all involve little children cursing and swearing. I\\xe2\\x80\\x99m not at all righteous but this has really gone too far in my account.<br /><br />Synopsis: The story about two guys got send to the big brother program for their reckless behavior. There they met up with one kids with boobs obsession and the other is a medieval freak.<br /><br />Just the name it self is not really connected with the story at all. They are not being a role model and or do anything but to serve their time for what they have done. The story is very predictable (though expected) and the humor is lame. And haven\\xe2\\x80\\x99t we already seen the same characters (play by Mc Lovin\\xe2\\x80\\x99) in so many other movies (like Sasquatch Gang?). I think I laugh thrice and almost fell a sleep.<br /><br />Well the casting was alright after all he is the one that produce the screenplay. And the acting is so-so as expected when you\\xe2\\x80\\x99re watching this type of movie. And the direction, what do one expect? This is the same guy who brought us Wet Hot American Summer, and that movie also sucks. But somehow he always managed to bring in some star to attract his horrendous movie.<br /><br />Anyway I felt not total riff off but a completely waste of time. Only the naked scenes seem to be the best part in the movie. Can\\xe2\\x80\\x99t really see any point why I should recommend this to anyone.<br /><br />Pros: Elizabeth Bank? Two topless scenes.<br /><br />Cons: Not funny, dreadful story, nudity and kids do not mix together.<br /><br />Rating: 3.5/10 (Grade: F)',\n",
            "       b\"With stunning cinematography and a thread of Kafkaesque absurdity, this movie had me from the simple yet fascinating opening scene. The movie plays much like a dream, and I think that may be why people either hate it or love it. Characters are drawn superficially and the story itself is slight and perhaps a little pointless. But these are failings of the movie but conscious choices. The film works isn't trying to work as history, but rather is a deconstruction of 1940s war movies. <br /><br />I would have trouble arguing that there was much real substance to the movie, but the movie is such a cinematic wonder that I was completely swept away. This is one of the most beautifully filmed movies ever, and there is a wild imagination in its style. I can completely understand why people would hate it, but I give it 9/10.\",\n",
            "       b\"i like Jane Austin novels. I love Pride and Prejudice and Sense and Sensibility books and movies, and I'm half way through Mansfield Park. But i couldn't stand Emma. I gave up on the book after 2 chapters, and by the end of the movie i couldn't care less about Emma. She didn't seem to change at all. Maybe it was Paltrows acting (which as excellent in Se7en) or my lack of interest for the movie. Dunno. <br /><br />The costumes are nice, but the dancing was clumsy compared to Pride and Prejudice dancing by Colin Firth and Jennifer Ehle.<br /><br />I gave it a 2 basically for the fact Knightly is bloody gorgeous, and although it as a rather patchy performance for Ewan McGregor, i liked his singing.\",\n",
            "       b\"Easily the greatest low budget horror film of all time. I first saw this movie when I was around nine years of age, and I have to say that it scared the hell out of me. Now that I'm all growed up, however, I see this movie for what it really is... a work of genius. Everyone, or at least everyone with any taste, has dreamed of seeing a snowman going around killing people, even if they won't admit it. I have always found something genuinely frightening about snowmen, so naturally, for a horror junkie such as myself, thismovie was a dream come true. Some people say that this movie is silly, or otherwise void of any intelligence... it's a movie about a serial killer snowman, what the hell did you expect? Anyone who gave this film a low score is obviously too uptight to sit back and have a good laugh at stupid one-liners and cheap gore. I love this movie for what it is, a comedy, and until the movie industry wises up and makes a serious horror flick about a killer snowman (which seems impossible, unfortunately) I will forever hold this great piece of indie horror close to my heart.\",\n",
            "       b\"The extended nuclear family, united in business as well as in personal life, is examined in this serious study of a grown son's conflict with his father's desire that he remain in the family business. This triggers a midlife crisis which may or may not be ameliorated by an affair and retreat to a shrink's couch. Very fine acting by all. A sleeper that deserves wide attention.\",\n",
            "       b\"Interesting film about an actual event that took place during the Civil War in Vermont. It kept my attention to the end and I don't regret viewing it. I haven't ever read any on this raid incident so I was curious to see if the rebels pulled it off. I enjoy historical films from that era.<br /><br />My major complaint is with the Confederate uniforms. They look too good!!! The acting was a little stiff at times. I like the old man eating the mashed potatoes because he didn't have any teeth. The wounded soldier playing fetch with a hound was a little strange. Overall, it was a descent film.\",\n",
            "       b'We\\'re talking about a low budget film, and it\\'s understandable that there are some weaknesses (no spoilers: one sudden explosives expert and one meaningless alcoholic); but in general the story keeps you interested, most of the characters are likable and there are some original situations. <br /><br />I really like films that surprise you with some people that are not who they want you to believe and then twist and turn the plot ... I applaud this one on that. <br /><br />If you know what I mean, try to see also \"Nueve Reinas\" (Nine Queens) a film from Argentina.',\n",
            "       b'Guy walking around without motive... I will never get those two hours of my life back. The guy kept on assuming identities and cheating on his pregnant wife. What was I thinking? How did this win a price anywhere? I understood he loved his father but other than that the movie was completely senseless to me. What was the purpose of walking so much and going to the funeral of a stranger for no apparent reason. How did this enrich his life??? Why did we have to see the dying old lady on her underwear????!!! Why???!!!!<br /><br />I though it would be deep or about something more interesting. I do not recommend the movie even to leave on while sleeping...',\n",
            "       b'Sandra Bernhard is quite a character, and certainly one of the funniest women on earth. She began as a stand-up comedienne in the 1970s, but her big break came in 1983 when she starred opposite Jerry Lewis and Robert De Niro in Scorsese\\'s underrated masterpiece, \"The King of Comedy\". Her film career never quite took off, though. She did make a couple of odd but entertaining pictures, such as \"Dallas Doll\" (1994) or \"Dinner Rush\" (2000), but the most amazing parts were those she created for herself.<br /><br />\"Without You I\\'m Nothing\" is undoubtedly her best effort. It\\'s an adaptation of her smash-hit off-Broadway show which made her a superstar \\xc2\\x96 and Madonna\\'s best friend for about four years. In ten perfectly choreographed and staged scenes, Sandra turns from Nina Simone to Diana Ross, talks about her childhood, Andy Warhol and San Francisco and performs songs made famous by Burt Bacharach, Prince, or Sylvester. Director John Boskovich got Sandra to do a 90-minute tour-de-force performance that\\'s both sexy and uniquely funny. If you are a Bernhard fan, you can\\'t miss out this film; it\\'s a tribute as well to her (weird) beauty as to her extremely unconventional talent as a comedienne. And it has influenced filmmakers in their work \\xc2\\x96 \"Hedwig and the Angry Inch\", for instance, would look a lot different if \"Without You I\\'m Nothing\" didn\\'t exist.',\n",
            "       b'This is my second time through for A Perfect Spy. I watched it 2 or 3 years ago and liked it. I like it still. It\\'s natural that it gets compared to the beeb\\'s other big Le Carre\\' series, Tinker Tailor Soldier Spy. Tinker Tailor focuses on the \"game\" spies play; Perfect Spy gives us the other axis - what kind of person a spy is. There are a number of themes that these movies share, along with others in the genre.<br /><br />Ambiguity - moral, sexual, interpersonal - which creates a multidimensional space of true vs. false, inside vs. outside, love vs. responsibility. In a way, these characters are happiest when they are being treated the most shabbily by those they love and respect - \"backstabbed\" in its various nuances.<br /><br />The theme of fathers and father-figures is also important. One of the most intriguing characters in A Perfect Spy is Rick, the main character Magnus\\' perhaps ersatz father. Throughout the story he betrays and is betrayed. A rogue who always manages to climb back up the ladder when he\\'s been toppled, who seems impervious to what others think of him, asks Magnus each time they meet, \"Do you love your old man?\" and never, \"Do you love me?\" Maybe it says this somewhere else, but A Perfect Spy is a love story.<br /><br />Another theme is that of malignancy. The nature of the business is to turn others - turn them against their government, against their friends and associates, turn them against their values and beliefs. In each of the Le Carre\\' movies I have seen, The Spy who Came in From the Cold, Looking Glass War, Tinker Tailor Soldier Spy, Smiley\\'s People, and A Perfect Spy, turning and being turned is the foundation of the tragedy. <br /><br />Finally, not so much a theme as an artistic touch - in each of these films there is usually only a single gun shot, or perhaps two shots bookending the story. Violence, torture, cruelty are always just beneath the surface. We see their results not as streams of blood or dank prison cells but in the the objects Le Carre\\'\\'s characters cling to as they are ineluctably sucked down into the morass.<br /><br />If you haven\\'t seen the films above, and you enjoy A Perfect Spy, you are in for a treat. I\\'d also recommend The Sandbagger series (Yorkshire TV), the 2nd and 3rd seasons of which begin to reach the level of this kind of complexity. The IPCRESS File and Burial in Berlin are nice, though light weight. For political intrigue try A Very British Coup, House of Cards and Yes, Minister/Yes, Prime Minister. <br /><br />If only a brit would set his hand to making The Three Kingdoms - there would be a film with intrigue and complexity.',\n",
            "       b'This movie is one of the many \"Kung Fu\" action films made in Asia in the late \\'70s - early \\'80s, full of cheap sound effects, dubbed dialog and lightning fast martial arts action. But unlike most films of this genre it also has a decent plot and lots of great comedy. When workers of a dye factory are forced out of their jobs by Manchu bullies, they hire a con-artist (Gordon Liu) to try to scare them off. When his attempt fails miserably, he cons his way into a Shaolin temple to learn to fight for real. But instead of making him a Kung-Fu student, the Master instead orders him to build a scaffolding to cover the roofs of all 36 chambers. Well, it turns out that while he\\'s performing these menial tasks (stacking and tying bamboo poles) that he\\'s learning the skills to be a Kung-Fu expert! It\\'s sort of like in Karate Kid when Mr. Miagi teaches Daniel the basics of karate by having him do routine household chores- \"Wax on, wax off\" et cetera. There\\'s lots of great comedy from beginning to end, and plenty of action at the end when Gordon Liu once again faces his Manchu tormentors. \"This time it\\'s not just tricks- it\\'s the real thing!\" Liu declares, proudly thumping his chest. If you like classic Kung Fu films you don\\'t want to miss this one!',\n",
            "       b'This had all the makings of a very good film -- good actors (Robert Loggia, Ellen Parker), a good plot (mysterious missile from space threatens to burn up the planet) and lots of stock footage (if the Air Force had film of jets firing rockets, it was used). Unfortunately, it is ruined by too much melodrama and an impossible time-line.<br /><br />The movie concerns a missile from space that is attacked by the Soviets and inadvertently diverted into a low atmospheric orbit. At under five miles and at a speed in excess of 4,000 miles, it emits an exhaust of a million degrees, burning up everything on the ground, including glaciers, Distant Early Warning (DEW) line bases and Eskimos.<br /><br />Every attempt at destroying the missile fails.<br /><br />The first flaws in this film appear early on. While we don\\'t expect much from low-budget films, some things can\\'t be forgotten -- like a little research. For instance, both the Soviets and the US fire anti-ballistic missiles that home in on the missile with unerring accuracy. However, the first successful ABM tests weren\\'t done until March of 1961 by the Russians.<br /><br />There is too much melodrama. Dr. Loring (Loggia) and his assistant Joan Woods (Ellen Parker) play their romance with about as much wood as a log cabin. Parker\\'s character cries and boo-hoos at Loggia\\'s sacrifice like she was at a screen test. Loggia is about as heroic as a bored businessman. A scientist (Phillip Pine) hams it up so much he makes William Shatner look like a thespian. A bus driver continually spits out end-of-the-world crap in scene after scene. The only good actor is the film narrator, played by veteran character actor Lawrence Dobkins (\"Naked City\").<br /><br />All of this could be overlooked if it wasn\\'t for the time-line. After the missile\\'s info is sent to DC, the Pentagon brings in a group of scientists. A general (Larry Kerr) announces that the missile will hit New York City in 63 minutes. After this, there are discussions by scientists and there is a deadly lull as word is sought from ambassadors to see if the missile is an attack from the Russians and if a response is necessary.<br /><br />The film shows the military being fully scrambled. Civil Defense people leave work and go to their stations. Eight million people scramble to fallout shelters while school buses pick up millions of kids (and we get to see the whitest New York City I\\'ve ever seen, though watching 50\\'s sci-fi films made it seems like this was the standard). The press is kept in the dark for tens of minutes. Then, incredibly, a man at the Pentagon announces that the missile will hit Ottawa, Canada in 51 minutes! All of the aforementioned action happened in 12 minutes! Then, to add fuel to the fire, Loggia somehow thinks of a way to stop the alien missile. He slowly produces a caseload of plutonium, loads it in a jeep and takes it from DC to a distant missile base to put it atop a missile. Along the way, he is knocked off the road by a wild driver, breaks down and then is carjacked. He finally gets the plutonium back and drives to the base to arm the missile. Again, all this in the same 63-minute time frame.<br /><br />The movie also irks the viewer by making it seem as if Ottawa might be saved, only to show men, women and children get roasted. The missile is then said to have five minutes to reach New York. Loggia is still driving to the base (4 more miles to go). He gets to the base and arms the missile, a two-minute countdown is then announced. All within five minutes. The boroughs of New York should have been at least scorched.<br /><br />By the way, the missile is destroyed if you haven\\'t guessed. The ABM warhead destroys it with a massive plutonium-based nuclear blast. Five seconds later, the blast dissipates and all is clear. Yeah, they caused a nuclear blast equivalent to 100 Hiroshimas on the outskirts of New York City and nothing happens.<br /><br />The film had all the elements necessary to be a good B film, but wasted them. Loggia played his character so lamely you didn\\'t care that he sacrificed himself in the end. You didn\\'t care about the other characters, not even the smarmy scientist played by Pine. The tension that should have moved the film along just wasn\\'t physically possible in the time-line allowed (it still wouldn\\'t be today, not even with Jack Bauer).<br /><br />This film is very difficult to find. As far as I know, it hasn\\'t been re-issued on any medium and for good reason. I don\\'t know if the film meant to be or if it was standard practice, but there\\'s a scene where the government sends all of the best scientists, military men and businessmen into deep shelters, saying they\\'re too valuable to lose. There isn\\'t a single woman or minority in the bunch. Hari Rhodes is the only black man in the film and he gets a brief bit playing a piano. It was worse than \"27 Days\" where an alien gives five Earthlings the chance to either save or destroy the planet and he doesn\\'t include any blacks or Hispanics.<br /><br />I saw this on a special Sci-fi night on Turner Classic Movies and I don\\'t expect it to show up again. If you do find a copy of this somewhere, you might want to put it up on Amazon.com.',\n",
            "       b'Horrible. I see many user comments on how great this show is. It truly is a Wanna-Be-Friends - Made in Taiwan knockoff. The jokes are lame as...and the plot is ridiculous. The actors are obviously struggling to be funny and are probably cringing when they hit those awful punchlines (if you can call them that). The bulk of the other users who have commented are obviously from another planet (or at least another continent). There are obviously reasons that TV companies cancel shows...and none of then are when shows are doing well. Make sense? Anyway, steer clear - even if it is raining and there is absolutely nothing else on this planet to do...go stand in the rain instead - more fun.',\n",
            "       b'Like a latter day Ayn Rand, Bigelow is la major muy macho in her depiction in the film of a few tough American hombres stuck in Iraq defusing roadside bombs set by the ruthless, relentless, child-killing Arab terrorists. As Bigelow posits the Iraq war as the backdrop of the grand stage of human drama, one veteran bomb expert gets blown up and another shows up to replace him in the dusty, hot, ugly rubble that is Iraq, and a new hero is born.<br /><br />The new guy is what John Hershey described in his book, and later the movie, The War Lover, as a sadistic wingnut who actually isn\\'t fit for civilian life, and requires the stimulation of war to sublimate and suppress his errant sexual desires. The war lover can only fully function in war, peacetime suffocates him. While Hershey chastised the war lover, (played in the film by Steve McQueen in one of his greatest roles) Bigelow glorifies him. The army needs war lovers, they are the bulwark of defense against our enemies. We can\\'t handle the truth, that it is war lovers who are the best soldiers, the toughest men. According to the unironic Bigelow, regular men are pussies, the war lover is a special breed, the last of the cowboys. So what if he wants to bare-back his men, or fondle an Iraqi boy? He is a throwback to the sex-and-death cult of war. In war, sex is a thankless, loveless, don\\'t-ask, don\\'t-tell kind of male bonding. Bigelow has no opinion on this; she just limits the options of masculinity in this ham-fisted attempt at realism. Only a war-lover can win the moral struggle between right and wrong, between American innocence and Arab perfidy. Bigelow disguises her racism and arrogance behind the ingenuous facade of journalism. She\\'s just another gung-ho yahoo depicting a brutal war against civilians as a moral triumph of the spirit.<br /><br />On the political front, Bigelow returns to the western genre and its relentless clich\\xc3\\xa9s again and again, ad nauseam: the wonderful world of the open frontier, which happens to be some one else\\'s country. (\"You can shoot people here\" says a soldier ); the tough but human black guy companion, the soldier with a premonition of death, the gruff, possibly crazy commanding officer, the college-educated fool who tries to befriend the enemy. You name it, Bigelow resurrects it.<br /><br />The man-boy love is palpable in scenes with the cute Arab boy who befriends the war lover, but Bigelow plays it straight; she doesn\\'t consummate the sex, just sanitizes it. What Bigelow really wants to show us is the ugly, sneering face of the Arab enemy. Any Iraqi who isn\\'t pure evil is either demented, hostile or up to no good, anyway. They all deserve to die for their impudence, and many of them do in this glib gore-fest film. The Iraqi women are all hysterical, they only make their presence known by screaming. They could be male stunt men in drag for all I know, you never see their faces. There is no female presence at all on base or in battle, although female casualty rates in Iraq would certainly disprove this.<br /><br />Bigelow goes through all the motions one by one. She glorifies war, she canonizes the sadist nut-case hero. The cowboys, surrounded by the subhuman Indians, prove their mettle by doing God\\'s work and subduing the wretched terrorist-infested hellhole with sheer bravado and suicidal mania. Toward the end, I felt like rooting for the Indians. In Bigelow\\'s world, though, no mercy or understanding ever makes it through. The Iraqis are dehumanized par excellence. The slaughter of civilians is just the dramatic backdrop to our hero\\'s psycho sexual struggle. Every U.S, bullet finds its mark. You have to love the guy, the war lover. It\\'s just his way, he is the true hero. He\\'s just a guy trying to get things done the hard way, and so what if he lusts for boy tang on the side.',\n",
            "       b\"I'm probably not giving this movie a fair shake, as I was unable to watch all of it. Perhaps if I'd seen it in a theater, in its original presentation, I might have appreciated it, but it's far too slow-moving for me.<br /><br />I read the book some 25 years ago and the details of the plot have faded from memory. This did not help the film, as it's something less than vivid and clear in its presentation of events.<br /><br />This is really four linked films, or a film in four parts, and was, I believe, intended to be seen over four nights in a theatrical presentation. I found Part I to be enjoyable enough, but it was all I could do to sit through Part II, which drags interminably. Reading Tolstoy's philosophizing is one thing. If you get a good translation or can read it in the original, his brilliant writing far outweighs any issues one might have with the pace of the story. On film, however, it's hard to reproduce without being ponderous.<br /><br />I have other issues with the parts of the film that I saw. It's very splashy, with a lot of hey-ma-look-at-this camera work that calls attention to itself, instead of serving to advance the story.<br /><br />Clearly, I'm missing something, but I just couldn't summon the enthusiasm to crank up parts III and IV.\",\n",
            "       b\"I recently saw this at the 2009 Palm Springs International Film. This is the feature length directorial debut of veteran Dutch actress Monique van de Ven and based on my observation it should be her last. I hate movies that are so implausible that you are picking apart practically every scene. This film immediately leaves you scratching your head. as it begins a young photographer and his girlfriend who works for an international aid organization are having a leisurely drive through the Taliban-controlled mountains Afghanistan having a conversation about their love when a rocket stops a truck in front of them. They get out of their vehicle to watch as Talliban fighters equipped with rocket launchers, machine guns, rifles, handguns and grenades execute all five people in the truck. Bob (Waldemar Torenstra) starts taking pictures of all this when he is spotted by one of the insurgents who lobs a hand grenade at them that kills his girlfriend. since they are with hand throwing distance they can't be more than 50 yards away yet he somehow gets away. His girlfriend is blown up and he takes a picture of the moment of the grenade impact that kills her and wins a prize as photographer of the year for the photo. Every scene and situation in this film as as ridiculous as it's opening. The following year Bob finds himself on assignment for National Geographic on a Dutch resort island where he meets Kathleen (Sophie Hilbrand) and inserts himself into her seedy underworld of international drug smugglers. Avoid this film. I would give it a 4.0 out of 10.\",\n",
            "       b'The Rookie kept me smiling from beginning to end. Dennis Quaid played the role to perfection. The little boy that plays his son was fantastic. He made this a father-son movie to remember. The messages are good ones. Follow your dreams. Failing at the pursuit is alright as long as you try. The excitement is palpable. I believe this movie will be a classic.',\n",
            "       b'I gather at least a few people watched it on Sept.2 on TCM. If you did you know that Hedy had to change her name to avoid being associated with this movie when she came the U.S. It was a huge scandal and I gather that the original release in the U.S. was so chopped up by censors that it was practically unintelligible. I watched because I had just seen a documentary on \"bad women\", actresses in the U.S. pre- movie censorship board set up in the early \\'30s. It looked to me as though they got away with a lot more than Hedy\\'s most \"sensational\" shots in \"Ecstasy\". In fact Hedy looked positively innocent in this, by today\\'s standards, and it was nice to see her early unspoiled beauty. It was a nice, lyrical movie to relax to. I loved it for what it was: a simple romance. I watched it after pre- recording it during a sleepless early A.M. I would love to see the first version released in the U.S. for comparison\\'s sake.',\n",
            "       b\"Strange enough, all the previous comments merely described the beginning and left the details over. I feel a necessity to confirm that this is a family work, since Marina Vlady was also Robert Hossein's wife, and the - excellent - jazz music was written by te director's father, Andr\\xc3\\xa9. Under these circumstances, no wonder it was a really good thriller, seen when issued and immediately identified with the music. The suspense was flawless, and maintained throughout until the end. Robert Hossein, at the time one of the best European players, managed to impose himself also as a top screen and stage director. He's still putting up great stage shows, with a preference for religious subjects.harry carasso, Paris, France\",\n",
            "       b'Enjoyed the movie very much. Certainly will leave the audience wanting to know more, and there is truly a lot more historically to find out!<br /><br />Did the production team fall to the temptation of over dramatization, particularly of the shooting event? There is a ton of interesting accurate material hinted at? Prince Albert\\'s contribution to UK and the monarchy warrants a movie on it\\'s own but granted that was apparently not part of the intention here.<br /><br />The costumes and sets are especially good but am I alone in thinking that this production (which judging by the length of titles at the end was certainly not a cheap one) wanted badly for a British Court historical etiquette expert beyond the Duchess of York? i.e. Did Princess Victoria really stuff an entire truffle/rissole(?) into her mouth while speaking to the Prime Minister in the company of His Majesty with her mouth full? <br /><br />\\'Could never really felt that sympathetic to Victoriain this movie, or indeed in her shoes at all. Yet loved the casting of the principals, whose acting was convincing, so did the script really allow us to really get to know them well? I always felt like a totally detached, uninformed outside observer, much more so than with \"Mrs. Brown\" or even \"The Queen\". Yet to be honest I still could not take my eyes off the screen, except that is for some of the more avant-garde camera techniques which were distracting from time to time.',\n",
            "       b\"This movie made it into one of my top 10 most awful movies. Horrible. <br /><br />There wasn't a continuous minute where there wasn't a fight with one monster or another. There was no chance for any character development, they were too busy running from one sword fight to another. I had no emotional attachment (except to the big bad machine that wanted to destroy them) <br /><br />Scenes were blatantly stolen from other movies, LOTR, Star Wars and Matrix. <br /><br />Examples<br /><br />>The ghost scene at the end was stolen from the final scene of the old Star Wars with Yoda, Obee One and Vader. <br /><br />>The spider machine in the beginning was exactly like Frodo being attacked by the spider in Return of the Kings. (Elijah Wood is the victim in both films) and wait......it hypnotizes (stings) its victim and wraps them up.....uh hello????<br /><br />>And the whole machine vs. humans theme WAS the Matrix..or Terminator.....<br /><br />There are more examples but why waste the time? And will someone tell me what was with the Nazi's?!?! Nazi's???? <br /><br />There was a juvenile story line rushed to a juvenile conclusion. The movie could not decide if it was a children's movie or an adult movie and wasn't much of either. <br /><br />Just awful. A real disappointment to say the least. Save your money.\",\n",
            "       b'How I got into it: When I started watching this series on Cartoon Network,I have to say that I\\'ve never seen anything like this,and it was the best. But when I started collecting the series on VHS,and years later on DVD part of Bandai\\'s Anime Legends collections. It was amazing,and truly worth watching. It had a lot of exploding action that will blow you out of your seat. And of course,the theme songs \"Just Communication\",and Rhythm Emotions\" were the best.<br /><br />Characters,and Gundams: My favorite characters in the show were:Heero,Duo,Relena,Treize,Lady Und,Noin,and Zechs. My favorite Gundams in the show that I liked the most are the Wing Zero,and Epyon,and of course the Altron,and Deathscythe I,and II.<br /><br />Meaning of the show: What this series also tells us that in real life,wars are very hard and we can sometimes win,or lose. But peace can also be hard to obtain,and I do believe the Gundam pilots are doing the right thing,and are trying to obtain world peace.<br /><br />But however,this show is truly the best of the best. So in closing to this review,after you watch this show,see the Movie Endless Waltz.',\n",
            "       b'Slither is a horror comedy that doesn\\'t really have enough horror or comedy to qualify as one or the other. It has one scene that is exceptionally good, any number of zingers that work, but very few real scares and not enough humor to maintain the movie. In addition, the script does not focus on the hero and heroine, and goes off kilter in several places.<br /><br />A major failing of this film is that it introduces and then leaves its hero (Fillion) to follow Grant Grant (Michael Rooker) as he is first introduced and then becomes the monster. This whole part of the film drags - Michael Rooker\\'s character isn\\'t that interesting to us as a person, and watching as he goes through a series of motions while acting in the monster\\'s interest might be interesting if this was Grant - Portrait of a Man Turning Into A Monster rather than a horror-comedy alien invasion movie. In the final analysis this movie\\'s problems are in the script - it isn\\'t that important to the audience how the monster acts or propagates. The purpose of a horror-comedy is to get the heroes backed up in a corner with shotguns and then throw bugs at them, with them cracking wise every time something frightening or disgusting happens. Instead we get an exploration of the alien\\'s habits and tactics that just makes this part of the movie drag. The ostensible heroine (Elizabeth Banks as Starla Grant) is more central to this part, but nonetheless I felt the movie had left its narrative track, unless it planned on following Grant Grant all the way to the end.<br /><br />When Fillion and his posse finally confront the alien the movie does begin to cook, but once again the problem is in the script. By this point that audience knows - and the characters should know - that Grant is not just suffering from some disease, and act accordingly (shotguns) - instead they continuously parley in the face of increasing evidence that this is not something that \"let us get you to a hospital\" is going to help. Although their reactions might have been human and real, these are characters in an action movie and simply should have done what the movie promised - delivered action. A lack of action scenes in a movie with as few ideas as this is a great failing.<br /><br />*** SPOILERS AHEAD *** After the first confrontation and the bursting of the alien larval sack (a minor character and perhaps the best scene in the movie) the script once again betrays the movie. At this point one of the characters is almost taken over by the alien and develops an insight into the alien. The writer-director (Gunn) chooses as this character a completely new character, rather than one of already developed minor characters. Why? Why did he need to introduce a completely new character more than an hour into the movie that becomes central to the plot? By the time this character is attacked, we know hardly anything about her and could care less about her, even though she is a winsome teenage girl in her bath. Had Gunn decided not to use this character and just used one of the established minor characters, he could have completely avoided introducing her family, and saved time and money. Furthermore, the hero and heroine would have been filled in on the alien\\'s plans without all the additional characters, and could have gotten around to blowing away aliens sooner and with more vigor.<br /><br />My last criticism is based on the movie\\'s look. Gunn is primarily a writer, or maybe it was budgetary constraints, but this movie looked ugly and uninteresting. Most of the action takes place at night in woods or on a field, and the screen simply looks drab. The sets in Wheelsy (the fictional town where the action takes place) look cheap. The whole movie looks cheap. Box Office Mojo states the films\\' budget was $15 million, newspapers say $29 million, and considering they didn\\'t use any name talent, I would say the money did not show up on screen. The monster is just repulsive, and rarely looks deadly.<br /><br />The last criticism is primarily based on the reality of the character\\'s actions. By the time Fillion and Co have begun hunting Grant/the alien, one woman has disappeared and Grant is known to have been mutilating animals. At this point I was expecting the FBI or at least the State Police to show up and take over from the hick Sheriff. A woman has disappeared and likely been murdered, and a local has been acting psychotic. Time to call the authorities. But basically I was hoping that would happen because I just wanted some characters who would show up and ACT.<br /><br />Although this movie is ostensibly a horror-comedy, the movie it bears the most resemblance to is Dreamcatcher in terms of monstrous invasion and the type of monster and its intentions. Whereas Dreamcatcher had much bigger problems with story (especially the entire Morgan Freeman subplot) and particularly the ending, in many ways it was stronger, primarily because the main characters were stronger, but more importantly because it looked beautiful. Although that may be anathema - preferring the movie that is weaker in general plot and structural spine because of production values - that just shows you how uninteresting I found the look of Slither.',\n",
            "       b'This movie was yet another waste of time... Why oh why do I keep renting crap like this?... someone please tell me... *sigh* Oh well. back to the movie at hand: Cube Zero is probably worth it if you REALLY REALLY enjoyed the first movie, (like I did), and just want to check out what\\'s up in the last (hopefully) movie scraped together just to keep some poor actors and screenwriters employed, then of course this is the movie for you. But if you are looking for a good movie with good acting and a fantastic plot... *evil grin* then this movie is definitely for you :-D.... OK I\\'m lying... At best this movie sucks. OK, I have to admit that certain elements to it was cool.. well.. coolish... and I laughed quite a few times, prolly at the wrong things, but nevertheless I was amused. :-) But all in all the few things that barely makes the \"ok\" category isn\\'t enough to make this movie worth it at all.. Unless you count \"Manos - Hand of Fate\" one of the top ten movies EVER!',\n",
            "       b'The story of \"A Woman From Nowhere\" is rather simple and pretty much adapted right out of a Eastwood Spaghetti Western: A mysterious stranger comes into a lawless town run by a kingpin and starts shooting up the place. Even the opening credits and music have that spaghetti feel: Sergio Leone and Ennio Morricone would be proud. The really interesting twists are that the stranger is a beautiful (!) woman, Saki (Ryoko Yonekura) on a Harley, and the location is in a town somewhere in Japan.<br /><br />In this actioner, there\\'s a considerable amount of gunplay, some of it good, some predictable, and other spots somewhat hokey, but it\\'s a whole lot of fun. Ryoko handles her guns with believability and aplomb and gives the thugs their due. It wasn\\'t much of an acting challenge for her as it was a physical challenge, but she handled things very well. She shows her acting skills much more as Otsu in the NHK drama, \"Musashi.\"<br /><br />I\\'d highly recommend film if you\\'re a Ryoko Yonekura fan (which I adoringly am) and/or a \"girls with guns\" movie fan and it does hold up to repeated viewings. To me, there\\'s something eminently and inexplicably appealing about \"girls with guns\" movies like \"La Femme Nikita\" and \"The Long Kiss Goodnight.\" And to have a gorgeous gal like Ryoko starring in it as well is just gobs of icing on the cake.',\n",
            "       b\"SPOILERS This is a gripping movie about grifters. But who is conning who here? When does the hunter turn into the prey? This gritty, dark movie is slow moving and seductive. It pulls you in and drags you down the proverbial garden path, only to waylay you just as you think you are safe.<br /><br />It has a riveting script, with good acting (at least from the leads). I didn't notice the background music, but it was never jarring, so it must have been done right.<br /><br />I was very surprised that I liked this movie, because I don't usually go for this genre but this one sucked me in and kept he hooked until the end.\"],\n",
            "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
            "array([b\"I LOVE Don Knotts, let me just say that up-front! He is an enormous talent and the best at what he does, which is portray a nervous, lovably befuddled loser thrown into a position of authority. He is fabulous in this role as Roy Fleming, the Reluctant Astronaut, but the film is pretty dull, really, even though as a kid my brother and I delighted in watching this and his other films. It's still worth watching but really it's a film that is best enjoyed by children. I'd categorize it as 100% family-friendly and something you could sit down and watch with your kids on a family night.<br /><br />As with all of Knotts' films, there's a great cast of beloved character actors and you can't help but smile when Knotts gives one of his shaky, open-mouthed stares, no matter how old and jaded you are.<br /><br />From an adult perspective, one thing I think that is great about this film is how it captures NASA in the 1960s -- all the new modern buildings, the hope, the optimism, the future! And I was surprised at how suave and studly Leslie Neilsen was back then. Only complaint about the story is Roy's love interest, a rather threadbare, unlikeable woman who can't give him the time of day until he becomes a big shot -- if you're like me, you'll be hoping that he gives her the shove-off at the end. Beware -- you'll be whistling the theme tune for days after watching, it's that catchy.\",\n",
            "       b\"Its spelled S-L-A-S-H-E-R-S. I was happy when the main character flashed her boobs. That was pretty tight. Before and after that the movie pretty much blows. The acting is like E-list and it's shown well in the movie. Not to mention it is so low budget that Preacherman and Chainsaw Charlie are played by the same person. The whole movie looks like it was shot with a camcorder instead of half way decent film. The only other reason I liked the movie was because Chainsaw Charlie and Doctor Ripper were funny. They said many stupid things that made me laugh. Other than that if you see this movie at Blockbuster do everyone a favor hide it behind Lawnmowerman 2. Anybody that thinks this movie is good should be mentally evaluated.\",\n",
            "       b\"There are some great philosophical questions. What is the purpose of life? What happens when we die? And WHY DO THEY MAKE MOVIES THIS BAD??? The premise is absurd. Thre acting is one dimensional. The special effects are overdone. And the movie is one unending gun battle among some of the lousiest shots Hollywood ever produced. But then, if they had been good shots, everybody would have been dead in the first five minutes and there would be no movie. Too bad it didn't happen that way. Tempted to turn it off several times, I stuck with it to see just how bad it could get. Glad I did because (SPOILER?) the last line is the crowning stupidity of the whole dopey, dismal scenario.It is not even worthy of second feature status at a third rate drive-in in off season. Apart from the general awfulness of the film, I worry deeply about its impact on young audiences. The Americans crank out crap like this and then wonder why events like Columbine happen. This is truly banal cinema on a Brobdingnagian scale!\",\n",
            "       b\"Personally I would advise people to stay clear of this movie. It's on the whole a bore to watch and the fighting is poorly choreographed. Slow and not very convincing. If you buy the Hong Kong Legends DVD release of this movie, then the only thing worth listening to is the Bey Logan audio commentary.<br /><br />But in any case, since when has there ever been a Ninja film worth watching. I cannot think of one and frankly do not wish to.<br /><br />Overall, when it comes to Movies, I have one golden rule: Avoid any films that contains the word 'Ninja'.\",\n",
            "       b'This is the kind of film that, if it were made today, it would probably star Sandra Bullock and Hugh Grant; actually, now that I think about it, this one is quite liable to be remade one day. It\\'s pleasant, but with no depth whatsoever. It suffers from the almost fatal miscasting of James Stewart in a role he is about 20 years too old for, and as a result there is no chemistry between him and the beautiful Kim Novak. Ernie Kovacs, in the small supporting role of an aspiring writer, is the only actor in the film whose performance approaches what you might call \"wit\". (**1/2)',\n",
            "       b'No sense going over the story since enough reviewers have done that. Here\\'s a few different slants on it from one of those \"religious nuts,\" as one bigoted reviewer puts it so tolerantly. <br /><br />1) \"Baby Face\" (1933) offers perhaps THE classic example ever put on film of how women can manipulate men with sex. There is a lot of truth to what Barbara Stanwyck demonstrates in this film: look cute, bat your eyelashes, offer your body for free.....and men will fall over themselves to help you out with whatever you want.<br /><br />In this case, it was job advancement with the ultimate goal of money.....lots of it. At least four men in this film do provide just that, even if it ruins their lives in the process. <br /><br />2) The ending - which many of the reviewers here seemed to hate - gives another great message: all the money and material goods in the world won\\'t make a person feel fulfilled. A sad comment that so many \"critics\" here would rather have immoral messages, preferring sleaze over substance. No surprise, I guess.<br /><br />Any way you look at it, the movie is entertaining start-to-finish and Stanwyck has some great lines, particularly in the beginning when she tells off her crude father and his unruly bar customers. At a little over 70 minutes, this film moves at a fast pace and is over before you know it.',\n",
            "       b'I thought How The Grinch Stole Christmas was a pretty good movie.It wasn\\'t horrible, nor was it great, but it was enjoyable to watch.I felt as if Jim Carrey got a little annoying at times.They made the Grinch seem like a special education person, when all he needed to be was evil and devious, but yet he turned out kind of retarded.I did think the scenery, when not inside the Grinch\\'s cave, was beautiful, and there was a few parts where I laughed, but most of the time I thought it was just annoying.This movie could\\'ve been \"SO\" much better if they had changed the Grinch\\'s personality, and they had included some more laugh scenes, because most of the humor wasn\\'t funny.I liked How The Grinch Stole Christmas anyway, but it\\'s not anything to get excited about seeing.',\n",
            "       b'What can I say? I think I have to write \"Spoiler alert\" and then \"reveal\" they used the F-word a LOT in this movie - like in every two sentences. I did not like this movie at all - too much hints on sexual perversions, sidesteps and cheating. And that swearing was totally out the window. I gave this movie \"3\" and two of those points are for Mira Sorvino\\'s sexy movements on the dance floor.',\n",
            "       b\"First off, I had my doubts just looking at the DVD box and reading it saying that it was about of bunch of teens gathering at a lake where they will find do or something. Any movie that has a premise like this has failed miserably, even as a slasher movie, except for the first Friday the 13th.<br /><br />I wanted to get up and stop watching the movie at least 10 times, but I just kept thinking that it had to get a little better. It didn't. Usually, I think every movie has something that you can take from it. This has nothing.<br /><br />Do yourself a favor, and find something constructive to do for 80 minutes. Like, give yourself papercuts, or eat dirt.\",\n",
            "       b'This has got to be a unique twists of two genres of ever seen. The giant monster movie genre with the living mummy movie genre. This unique blend makes for a unique and compelling story. The casts is outstanding, including TOM BOSLEY who as far as I know never has been in a horror movie before, ever. The effects are impressive and the idea of a giant mummy filled with smaller mummies is a cool one. My one complaint, I just wish we saw more of the giant mummy, but other then that I think they did a great job. The dialog, the characters and the story was perfect. The acting was wonderful. This has got to be the best movie to come out of the sci-fi channel. You heard me, the best movie to come out of the sci-fi channel. I give THE FALLEN ONES 9 OUT OF 10.',\n",
            "       b\"De Grot is a very good film. The great plot comes from the novel by Tim Krabb\\xc3\\xa9, who also adapted this story for the screen. Some really top-class acting, not only by Van Hu\\xc3\\xaat, but especially by Marcel Hensema, who mostly did TV-work prior to his performance of Axel van de Graaf. The film seems to kick of as a thriller, and sets an excellent mood. Then we start to learn about Egon Wagter and Axel van de Graaf, and the story is revealed bit by bit in a very compelling flash-back structure, which adds to the more romantic aspect and the character-driven drama of the movie. In the end this all culminates into an emotional ending, that will grab audiences by their throats. Make sure you know as little as possible about the plot when you are going to see this movie. A must-see, especially if you liked 'Spoorloos' (The Vanishing's original screen adaptation).\",\n",
            "       b\"Sudden Impact is a two pronged story. Harry is targeted by the mob who want to kill him and Harry is very glad to return the favour and show them how it's done. This little war puts Harry on suspension which he doesn't care about but he goes away on a little vacation. Now the second part of the story. Someone is killing some punks and Harry gets dragged into this situation where he meets Jennifer spencer a woman with a secret that the little tourist town wants to keep quiet. The police Chief is not a subtle man and he warns Harry to not get involved or cause any trouble. This is Harry Callahan Trouble follows him. The mob tracks him to this town and hell opens up as Harry goes to war. Meanwhile the vigilante strikes again and the gang having figured it out is ready for her. Jennifer Spencer is caught and Harry comes to her rescue during the film's climax. Sudden Impact is not the greatest Dirty Harry but at the time it gives us a Harry that is very much an anti hero ready to go to war just to pursue Justice. Again not the best not the worst but the one with the most remembered line. Go Ahead Make your day.\",\n",
            "       b'Saturday Night Live, National Lampoon, and SCTV alumnus are all together in a sometimes funny sketch film.<br /><br />However, it is very interesting to watch now, at the start of 2005. Twenty years after this movie is supposed to take place, look at how many of their gags have become absolutely true: There is a mock movie trailer, that probably wasn\\'t even clever at the time, for something called \"The Pregnant Man\" which came true with Arnold Schwarzenegger\\'s dumb movie \"Junior\" There is a commercial spoof, that probably wasn\\'t even clever at the time, for something featuring Sammy Davis Jr. and Jackie Onasis called \"Celebrity Wrestling\" which has now come true with a popular show called \"Celebrity Boxing\" There is a mock movie trailer, that probably wasn\\'t even clever at the time, that features John Candy in a movie about a severed head. Watch this trailer and look how similar it\\'s shots and plot are to Frank Hellenlotter\\'s Basket Case!! And finally there is an ad for a late late show documentary about \"a dead dream, the only two left ...\" The name of the documentary is ... THE LAST HIPPIES! LOL.<br /><br />Four prophecies come true!',\n",
            "       b'There are no words to explain how bad NIGHTMARE WEEKEND is. It simply defies description. Something about a computer that can change personal objects into silver balls that enter the victims\\' mouth, which kills them or turns them into zombies. The whole thing is so wonky that it\\'s stunning. There\\'s also a girl with personal computer in her room and the computer talks via a hand puppet!!!!!!!! I\\'m not making this stuff up. The computer also controls things like cars, even though there\\'s nothing linking the computer with the vehicle.<br /><br />The \"film\" is total trash. Surreal bad trash. Spectacularly, one-of-a-kind bad trash. There\\'s a lot of sex scenes thrown here and there, which aren\\'t very hot or erotic. There\\'s even one scene where a woman seemingly makes love or wants to French kiss a tarantula, which had me rolling on the floor.<br /><br />Definitely one of the worst movies ever made. Up there with the equally wretched direct-to-home video BOARDINGHOUSE, or BOOGEYMAN II (both NIGHTMARE WEEKEND and BOOGEYMAN II have scenes with a killer toothbrush!). At least it\\'s fun to watch it and try to make sense of whatever is going on.',\n",
            "       b\"I consider this film one of the worst in the Nightmare series. It was so boring that I couldn't remember a thing 20 minutes after the film was over, it even tires me to write a review on it.<br /><br />Okay, #4 was a joke and Freddy was the joker. #5 tried to return to the roots of the series. It was darker and more atmospheric than Nightmare 4, which is a good thing, basically. They tried to shoot a horror film instead of a comedy. Unfortunately they forgot to add suspense and scares. Because of that Nightmare 5: The Dream Child is neither funny nor is it scary. What we actually get is a boring film with the usual bad actors (maybe with the exception of Lisa Wilcox).<br /><br />The plot (Freddy killing Lisa's friends by using the dreams of Lisa's unborn child) has a good base but it just isn't enough for 90 minutes of film. Sometimes the story gets very confusing (maybe because there isn't any) and you can't stop wondering what the filmmakers were aiming at. The screenplay must have had more holes than Swiss Cheese and the film therefore was very cheesy itself (let me say that I don't like cheese though, even if I am from Switzerland). Not even the special effects were as good as for example in part 4.<br /><br />Don't bother to rent/buy this film if not for completeness, it's quite a mess.<br /><br />My rating: 4/10 (get used to it, #6 is also a messy one...)\",\n",
            "       b'i loved this movie it was one of the years best pornos i remember watching it on starz or some god damn thing but it was great. i only saw like half of it and i taped it and all i can say is i loved every minute of what i saw. i didnt sleep for weeks after i saw this movie (although i was very tired.)',\n",
            "       b'Wizards of the Lost Kingdom is a movie about a young prince (Simon) who is banished from his kingdom due to his father (the king) being killed by the cliche \"evil adviser\". This movie\\'s about Simon\\'s adventures. The special effects, plot, acting, and generally everything about this movie is BAD. However, it\\'s so bad that it\\'s funny. You will keep watching this movie simply because it\\'s so bad it\\'s funny, and, like the other reviewer of the movie said, it\\'s so bad it\\'s good.',\n",
            "       b'When I saw this at a shop I thought it looked really good and original. Like Wolfs Creek meets Texas chainsaw massacre, and I mean it only cost three quid (around $6). To be honest I don\\'t think it was even worth that.<br /><br />It seemed like the directors- the \\'butcher brothers\\' couldn\\'t decide whether wanted to do a artsy sort of horror or a gory slasher horror. It ended up with a clich\\xc3\\xa9 ridden gory sadistic hour and fifteen minutes with all the characters being one dimensional and you couldn\\'t care less what happened to them but to try to make the audience care about the characters they added a useless monologue at the end and the beginning of the film which to be perfectly honest wasn\\'t needed.<br /><br />The only good part really was the middle/end- I won\\'t ruin it for you. But that was the only \"good \"part.<br /><br />Overall a pointless watch. It felt like a two hour film but was in fact only 75 minutes. If you want an artsy film-don\\'t bother. If you want a slasher movie- don\\'t bother- The film moves so slowly with nothing ever happening.',\n",
            "       b'By no means a masterpiece, and far from Errol Flynn\\'s best, Istanbul still has much going for it. The locations and beautiful technicolour cinematography, bring us back to a time long since past. Errol Flynn does show moments of his past glory, and is OK as Jim Brennan, a pilot who\\'s past comes back to haunt him. The picture is actually a remake of 1947\\'s \"Singapore\", and the story seems awfully contrived and cliche\\' by today\\'s standards. Also many of the supporting cast seem to be simply \"going through the motions\" in this picture. Many people have also compared it to one of the all time greats, CASABLANCA. While watching the film, I could see many of the similarities, but hey, Casablanca has inspired countless imitators, so take that for what it\\'s worth. In closing, if you are a fan of Flynn, or old fashioned love stories, you might want to give this film a look. Otherwise, I\\'d recommend Casablanca, or The Maltese Falcon, as a good introduction to some of Hollywood\\'s classics....',\n",
            "       b'I really can\\'t remember who recommended this, but they said it was one of their favorite films. It is certainly a strange one - like rubbernecking at a highway accident.<br /><br />Someone said that truth is stranger than fiction, and the truth here is something to see. I really can\\'t understand how a fictionalized account of this documentary is to be released this year. How can you improve on this? The aunt and cousin of Jackie Kennedy remove themselves from New York Society and hide in the Hampton\\'s. In the process they become recluses and what is best described as \"crazy cat ladies.\" They would have stayed hidden had not the city move to condemn the property for the filth and the subsequent rescue by Jackie. This film was done after that rescue. All during, you couldn\\'t help but think, \"how bad was it before?\" It\\'s a look at high society from the darker side, and it is utterly fascinating.',\n",
            "       b\"I saw this show about 3-4 years ago. It was dam Funny! When i first time i saw it was playing on ETV(Estonian Television) And i started to like it. Too bad that that show is on bad time for me. Hyde is like a cool guy who likes to sing Frank Sinatra! And he comes on stupid ideas. He got these glasses which h are brown. I like it . And there's FeZ. The group Pervert. We all know what he does when his alone..... He wants to get laid badly. He even had it with his boss in one episode.His from India. And there is Michael , The stupidest guy on whole group , probably stupidest in town and his a cop! He is so stupid that i remember follows: Hyde says: Did u called cops ? - No Michael comes in and says. Does anyone know how to turn off siren? He is a town playboy. Then comes Jackie , who is former girlfriend of Michael and then she's Hyde's girlfriend. Then is Eric Who's son of grumpy war veteran and son of Kitty the housewife. His one big pussy. But he loves Donna , his girlfriend with who they plan for they're marriage. Donna is one hot girl. Hmm what i forget? ah Hyde lives in a basement .\",\n",
            "       b'*WARNING* Contains MANY SPOILERS!<br /><br />Let me start by saying I have a huge respect for Gillian Anderson\\'s incredible talent as a varied and versatile actress - which is why I cannot comprehend her reasons for agreeing to make this film once she saw the script (or lack thereof.) <br /><br />The premise of the film was, in my opinion, a great idea and there were some genuinely thought-provoking themes in there but it ended up like a collapsed souffl\\xc3\\xa9. It exemplifies why I hate 99% of British cinema. It feels too long, it\\'s tedious, for the most part, and not a lot happens after the first twenty minutes. Just when you think there\\'s a chance of it picking up some speed it disappoints like Paula Radcliffe running a marathon. With little imaginative directing and a minimalist plot, there isn\\'t much to keep the audience from nodding off into their popcorn. As for the script I can only surmise that the writer was trying to save a few trees, with the average scene reading something along the lines of \"Alice: F*** OFF! (Adam stares. Adam runs off into woods)(Alice follows) Alice: ADAM! ADAM!\" I suspect that, word for word, the actors probably got paid more than Kate Moss did for her Virgin Mobile adverts. What few lines there were didn\\'t have a lot of variation with a frequent use of the f-word that would make Bridget Jones\\'s friend, Shazza, proud. There is little establishment of the main characters before the main sordid event which leaves the audience lacking much sympathy for the characters beyond an automatic \\'Oh that\\'s terrible\\' reaction.<br /><br />Alice isn\\'t the kind of woman who courts sympathy either. She\\'s got a great job, an expensive London apartment with roof space to die for yet she comes across on screen as conceited, bitter and dissatisfied before her life takes a turn for the worst. After the attack a few layers are peeled back which sort-of explain why she is this way to start with; she grew up with a tough-as-old-boots soldier who thought that teaching her how to shoot his gun was the ultimate expression of love so, instead of following in his footsteps, she ran away to the big city in search of something to make her feel like her life is worth living. Instead she found a group of stereotypical middle-class Toffs who look down on anyone not rich enough to drive a Lexus and the luxuries that come with an integrated security/entertainment system (i.e. becoming Mrs Robinson to a wanna-be Cockney wide-boy electrician) Someone pass me a tissue. The one saving grace of this character is that she is played by Gillian Anderson. In the hands of a lesser actress she would\\'ve been intolerably one-dimensional but Ms Anderson actually manages to inject a few fleeting moments of humanity into this otherwise lifeless human being, most notably when she\\'s sincerely apologising for her road rage in a vain attempt to stop her attackers from continuing their assault.<br /><br />I can\\'t say that Adam fared much better either. Danny Dyer played him well as a fish-out-of-water Jack the Lad but a good performance couldn\\'t save him from both the lack of a script and the total absence of any character background. <br /><br />This film relied mostly on shock value but the timing was off and it felt far too engineered from beginning to end. As for the shock, the most shocking thing about this film is the unashamed demonstration of how painfully thin Ms Anderson has become; it was almost as unsettling to see as the brutal attack scenes. On a side note, only in a British film would a gang of violent sex attackers take the time to offer each other contraception before continuing to cheer their mates on - talk about stiff-upper-lip taken to the extreme! If this is the kind of film that the National Lottery is donating money to make then I\\'m not surprised that fewer and fewer people are choosing to spend their pound each week. <br /><br />Saying that I hated this film is giving it too much credit, I didn\\'t care enough about any of the characters to warrant that strong an emotion. I want that one-and-a-bit hours of my life back, please!',\n",
            "       b\"Could anyone please stop John Carpenter from continuously and deliberately ruining his reputation? How low can you go? It seems this man has lost any self respect.<br /><br />This episode looks like it has been done by a film student, it isn't even worth beginning to talk about WHAT was bad, because it was just a borefest, directed by somebody with no talent as a filmmaker or without any motivation...<br /><br />Come on, Mr. Carpenter, please retire immediately with a rest of self-esteem and stop spilling out trash like this in a bad tradition from Escape from L.A. to Ghosts of Mars.<br /><br />Get drunk instead.\",\n",
            "       b'I found this movie hilarious. The spoofs on other popular movies of that time were some of the funniest I have seen in this sort of movie. Give it a try. If you saw the movies that this movie is spoofing, and you get the humor, you should enjoy the movie.<br /><br />I (and the others who watched the movie with me) felt the funniest part in the movie (this is not a spoiler because I will NOT tell you what actually happens) was a scene with the \"flashy thingy\" from MIB. When they first discover the device and do not know what it is does... and then again later in the movie... you\\'ll understand when you get there.<br /><br />My only complaint about the movie is that I have never been able to find it in DVD so that I could buy a copy.',\n",
            "       b'Evidently when you offer a actor enough money they will do anything. I am not sure how much John Rys-Daves got, but most of the money he made should go to his fans as an apology for even being associated with such a ROTTEN movie. The special effects were worse then effects from the 1950\\'s B movies and the acting of the rest of the cast was even worse. As to how bad the acting was a child gave the second best performance in my opinion. The English was terribly accented and I think no one could really even speak English they just memorized how the words should sound instead of memorizing the script and trying to make their character both \"life-like\" and real.',\n",
            "       b'I saw this film (it\\'s English title is \"Who\\'s Singing Over There?\") at the 1980 Montreal International Film Festival. It won raves then... and disappeared. A terrible shame. It is brilliant. Sublime, ridiculous, sad, and extremely funny. The script is a work of art. It\\'s been 19 years and I\\'ve seen only a handful of comedies (or any other genre, for that matter) that can match its originality.',\n",
            "       b'Dumb is as dumb does, in this thoroughly uninteresting, supposed black comedy. Essentially what starts out as Chris Klein trying to maintain a low profile, eventually morphs into an uninspired version of \"The Three Amigos\", only without any laughs. In order for black comedy to work, it must be outrageous, which \"Play Dead\" is not. In order for black comedy to work, it cannot be mean spirited, which \"Play Dead\" is. What \"Play Dead\" really is, is a town full of nut jobs. Fred Dunst does however do a pretty fair imitation of Billy Bob Thornton\\'s character from \"A Simple Plan\", while Jake Busey does a pretty fair imitation of, well, Jake Busey. - MERK',\n",
            "       b'A pre-code stunner with Stanwyck playing a speakeasy whore who sleeps her way to the top. These pre-code flicks really let it all go with nothing left to the imagination. Stanwyck is outstanding as Lilly the daughter of a speakeasy owner/father who sold more than booze to his patrons(johns).After the old man dies(good!) Barb heads for the big city for better things.She uses her female attributes to sleep her way to the top. John Wayne makes a poor \"cameo\" and proves that actors get better with age and an acting coach. I loved the banter and strong lines between the actors. I highly recommend this film to all film buffs and to watch Stanwyck who is great and beautiful as Lilly.',\n",
            "       b'The movie was very moving. It was tender, and funny at the same time. The scenery was absolutely beautiful! Peter Faulk and Paul Reiser gave award winning performances. Olympia Dukakis was great. I understand due to the story line her part had to be brief, but I did wish I could have seen more of her-she is a true pro.You will be able to recall experiences from your own life , hopefully in a positive way after seeing this movie. We were fortunate to see Paul Reiser at a Q and A after the viewing. He is a wonderful man, clever, eloquent and a \"real Person\". It was truly an enjoyable night out!This is a must see movie. You will be so grateful you went.',\n",
            "       b\"This Chinese movie made me feel so many similarities with members of a culture I don't belong and are far from. In an almost Buddhist approach, the film helps one to relate to each character, and to the happiness of doing the simple routine things.<br /><br /> All actors are brilliant, and Xu Hzu exudes kindness and wisdom, yet also vulnerable and mean. Er Min, the retarded brother, shows us that intelligence and wisdom are not equal, and that wisdom comes to and from the most disparate persons in this universe. A different China, this is far from the Chinese realism, yet, it has lots of humanity and realism of a different kind.<br /><br />Get it. You won't be disappointed.\",\n",
            "       b\"Hm. While an enjoyable movie to poke plot holes, point out atrocious acting, primitive (at best) special effects (all of which have caused me to view this movie three times over the past six years), Severed ranks among the worst I've ever seen. I'm never sure who the protagonists are, all I know is that the killer uses a portable guillotine, as seen in the dance floor murder scene. All in all, I don't really like the movie, because only the first 30 minutes are enjoyable, the rest is a mishmash of confusing dialog and imagery that fail to progress the story to a logical conclusion (which I can't remember anyway).\",\n",
            "       b\"I could not agree less with the rating that was given to this movie, and I believe this is a sample of how short minded most of spectators are all over the world. Really... Are you forgetting that Cinema used to be a kind of art before some tycoons tried to make it only entertainment? This movie is not entertainment, at least not that easy entertainment you get on movies like Titanic or Gladiator. It has style, it is different, it is shocking... That's why most of you have hated it so much: because it does not try to be pleasing to you. It's just a story, a very weird one I admit, but after all, only a weird story. It is not a great story, not even a great cinema work, but I believe it is worth a 7-stars rating only for the courage of both author and director to shot a story that is not made to please the audience, thus selling billions of copies and making the big studios even richer. This movie is, for me, European-artistic-like movie made in the US, and everyone involved in the making of it deserves respect. Be it for the courage, or be it for the unique sense of humor.\"],\n",
            "      dtype=object)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "batched_train_ds = train_ds.batch(32)\n",
        "\n",
        "for i, element in enumerate(train_ds):\n",
        "  print(element)\n",
        "  if i >= 2:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIhmW-hCvPS2"
      },
      "source": [
        "# 단어를 집합으로 처리하기 : BoW 방식\n",
        "순서를 무시하고 토큰의 집합으로 다루어 보자.  \n",
        "개별 단어(유니그램) 을 사용하거나 또는 연속된 토큰 그룹(N그램) 으로 국부적인  순서 정보를 유지할 수 있음.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3CTge5xv7NC"
      },
      "source": [
        "TextVectorization 층으로 처리하여 멀티-핫-인코딩된 이진 단어 벡터를 만들어 보자 (유니그램)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXnlLEFCvOl-",
        "outputId": "a0f9644f-e36f-4555-d0fb-08028cf2f890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(32, 20000), dtype=int64, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 0, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32, 20000), dtype=int64, numpy=\n",
            "array([[1, 1, 0, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32, 20000), dtype=int64, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
            "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import TextVectorization\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens = 20000, # 가장 많이 등장하는 2만개 단어로 어휘 사전을 제한\n",
        "    output_mode = \"multi_hot\", # 멀티-핫 이진 벡터로 출력 토큰을 인코딩\n",
        ")\n",
        "\n",
        "text_only_train_ds = train_ds.map(lambda x, y : x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "\n",
        "for i,element in enumerate(binary_1gram_train_ds):\n",
        "  print(element)\n",
        "  if i >= 2:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF0-F_Nfxvzg"
      },
      "source": [
        "이제 이 절의 모든 예제에서 사용할 모델 생성 함수를 만들어 보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTGbxVT0xvFo"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens = 20000, hidden_dims = 16):\n",
        "  inputs = keras.Input(shape = (max_tokens,))\n",
        "  x = layers.Dense(hidden_dims, activation = \"relu\")(inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = \"rmsprop\",\n",
        "      loss = 'binary_crossentropy',\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PntbDWtyxY9"
      },
      "source": [
        "마지막으로 훈련을 진행해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8vndoEcywgd"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    binary_1gram_train_ds.cache(),\n",
        "    epochs = 10,\n",
        "    validation_data = binary_1gram_val_ds.cache(), # 메모리에 캐싱\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjJDDtIX39wq",
        "outputId": "489ce57c-2ca1-48b6-d275-109f85a6b38b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 822ms/step - accuracy: 0.8846 - loss: 0.2924\n",
            "테스트 정확도 : 0.8881999850273132:.3f\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"테스트 정확도 : {model.evaluate(binary_1gram_test_ds)[1]}:.3f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW6XTsAr1E_e"
      },
      "source": [
        "## 이진 인코딩을 사용한 바이그램\n",
        "단일 단어가 아닌 N-gram을 사용하여 국부적인 순서정보를 BoW 표현에 추가해보자    \n",
        "TextVectorization 층은 바이그램, 트라이그램을 포함하여 임의의 N-gram을 반환할 수 있음.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqBp69v502q7"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams = 2,\n",
        "    max_tokens = 20000,\n",
        "    output_mode = 'multi_hot',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOfUWKXP4dHN"
      },
      "source": [
        "이진 인코딩된 바이그램에서 훈련한 모델의 성능을 확인해 보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVuHRTfY4muP"
      },
      "outputs": [],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB7mcbkY4fWI"
      },
      "outputs": [],
      "source": [
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "Rce3iKDX5Avl",
        "outputId": "9fe7b527-91de-407e-aa89-cdc42a33b7c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1237s\u001b[0m 2s/step - accuracy: 0.7701 - loss: 0.4850 - val_accuracy: 0.8932 - val_loss: 0.2733\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.2533 - val_accuracy: 0.8970 - val_loss: 0.2750\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9288 - loss: 0.2234 - val_accuracy: 0.9012 - val_loss: 0.2933\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1924 - val_accuracy: 0.8992 - val_loss: 0.2969\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9465 - loss: 0.1779 - val_accuracy: 0.8956 - val_loss: 0.3215\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.1705 - val_accuracy: 0.8998 - val_loss: 0.3332\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1780 - val_accuracy: 0.8922 - val_loss: 0.3490\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9535 - loss: 0.1704 - val_accuracy: 0.8950 - val_loss: 0.3631\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1571 - val_accuracy: 0.8978 - val_loss: 0.3798\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9608 - loss: 0.1574 - val_accuracy: 0.8910 - val_loss: 0.3817\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1198s\u001b[0m 2s/step - accuracy: 0.8936 - loss: 0.2778\n",
            "테스트 정확도 : 0.894\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    binary_2gram_train_ds.cache(),\n",
        "    validation_data = binary_2gram_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")\n",
        "\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"테스트 정확도 : {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F827UqJG5mtM"
      },
      "source": [
        "# TF_IDF 인코딩을 사용한 바이그램\n",
        "이 표현에서는 개별 단어나 N-그램의 등장 횟수를 카운트한 정보를 추가할 수 있음.  \n",
        "즉, 텍스트에 대한 단어의 히스토그램(histogram)을 사용함.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmPLYUQK5yxo"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams = 2,\n",
        "    max_tokens = 20000,\n",
        "    output_mode = \"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHaeWcJP54Mt"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams = 2,\n",
        "    max_tokens = 20000,\n",
        "    output_mode = \"tf_idf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13niUB7990bC"
      },
      "source": [
        "이 방식으로 새 모델을 훈련해 보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "bYqeC_oW917v",
        "outputId": "03446a05-06fd-491a-b731-378f912b6f48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1194s\u001b[0m 2s/step - accuracy: 0.7029 - loss: 0.6119 - val_accuracy: 0.8780 - val_loss: 0.3127\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - accuracy: 0.8500 - loss: 0.3630 - val_accuracy: 0.8784 - val_loss: 0.3043\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8768 - loss: 0.3065 - val_accuracy: 0.8734 - val_loss: 0.3307\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8881 - loss: 0.2797 - val_accuracy: 0.8838 - val_loss: 0.3213\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.2583 - val_accuracy: 0.8670 - val_loss: 0.3390\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.2397 - val_accuracy: 0.8520 - val_loss: 0.3767\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.2356 - val_accuracy: 0.8728 - val_loss: 0.3569\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9095 - loss: 0.2312 - val_accuracy: 0.8700 - val_loss: 0.3643\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2378 - val_accuracy: 0.8672 - val_loss: 0.3714\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9057 - loss: 0.2220 - val_accuracy: 0.8582 - val_loss: 0.3975\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1128s\u001b[0m 1s/step - accuracy: 0.8727 - loss: 0.3111\n",
            "테스트 정확도 : 0.873\n"
          ]
        }
      ],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x ,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4\n",
        ")\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    tfidf_2gram_train_ds.cache(),\n",
        "    validation_data = tfidf_2gram_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")\n",
        "\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"테스트 정확도 : {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_vtevNh-7Gt"
      },
      "source": [
        "# 단어를 시퀀스로 처리하기 : 시퀀스 모델 방식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW1StjHsAGRo"
      },
      "source": [
        "시퀀스 모델을 구현하려면 먼저 입력 샘플을 정수 인덱스의 시퀀스로 표현해야 함.(하나의 정수가 하나의 단어를 나타냄) 그다음 각 정수를 벡터로 매핑하여 벡터 시퀀스를 얻고, 마지막으로 이 벡터 시퀀스를 1D 컨브넷, RNN, 트랜스포머와 같이 인접한 벡터의 특징을 비교할 수 있는 층에 전달함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ZrrboIAJND"
      },
      "source": [
        "## 정수 시퀀스를 반환하는 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8T8ZuThAML_"
      },
      "source": [
        "먼저 정수 시퀀스를 반환하는 데이터셋을 준비하자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EDZBJTYRsd7p"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "text_only_train_ds = train_ds.map(lambda x, y : x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zw_HArIR-UvN"
      },
      "outputs": [],
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens = max_tokens,\n",
        "    output_mode = \"int\",\n",
        "    output_sequence_length = max_length, # 적당한 입력 크기를 유지하기 위해 입력에서 600개 단어 이후는 잘라 버림\n",
        "    # 평균 리뷰 길이가 233개의 단어고 600개의 단어보다 긴 리뷰는 5%뿐이므로 합리적인 선택임.\n",
        ")\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)\n",
        "\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)\n",
        "\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKwnMS_RDBLB",
        "outputId": "861f9619-6b4e-40da-8507-177d0cb7700a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(32, 600), dtype=int64, numpy=\n",
            "array([[   2,   87, 1227, ...,    0,    0,    0],\n",
            "       [ 234,   11,  427, ...,    0,    0,    0],\n",
            "       [  11,  387,    7, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  10,  118,   57, ...,    0,    0,    0],\n",
            "       [ 256,    9,   44, ...,    0,    0,    0],\n",
            "       [   2,  152,   43, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
            "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32, 600), dtype=int64, numpy=\n",
            "array([[ 11,   7,   2, ...,   0,   0,   0],\n",
            "       [  8,  34, 565, ...,   0,   0,   0],\n",
            "       [  2,  18,  14, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [169, 715,  60, ...,   0,   0,   0],\n",
            "       [ 10, 207,  11, ...,   0,   0,   0],\n",
            "       [ 10,  95,  22, ...,   0,   0,   0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
            "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(32, 600), dtype=int64, numpy=\n",
            "array([[1457, 7912,    7, ...,    0,    0,    0],\n",
            "       [1493, 7732,    7, ...,    0,    0,    0],\n",
            "       [  63,   30,  159, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  87,    5,   32, ...,    0,    0,    0],\n",
            "       [  11,    7,   56, ...,    0,    0,    0],\n",
            "       [ 513,   10,   68, ...,    0,    0,    0]])>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
            "array([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
            "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0], dtype=int32)>)\n"
          ]
        }
      ],
      "source": [
        "for i, element in enumerate(int_train_ds):\n",
        "  print(element)\n",
        "  if i>=2 :\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjfpypJrFTXA"
      },
      "source": [
        "## 원-핫 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhQxB9r7BKzX"
      },
      "source": [
        "이제 모델을 만들어 보자.\n",
        "정수 시퀀스를 벡터 시퀀스로 바꾸는 가장 간단한 방법은 정수를 원-핫 인코딩하는 것임(각 차원은 어휘 사전에 있는 하나의 단어를 표현)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "7zXtJApbGpfb",
        "outputId": "6d05a226-f268-40ac-9b6e-1b316881ead6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m5,128,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,513</span> (19.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,128,513\u001b[0m (19.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,513</span> (19.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,128,513\u001b[0m (19.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 367ms/step - accuracy: 0.5734 - loss: 0.6624 - val_accuracy: 0.8272 - val_loss: 0.4725\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 369ms/step - accuracy: 0.8350 - loss: 0.4249 - val_accuracy: 0.8630 - val_loss: 0.3548\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 366ms/step - accuracy: 0.8826 - loss: 0.3286 - val_accuracy: 0.8862 - val_loss: 0.2936\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 364ms/step - accuracy: 0.9040 - loss: 0.2766 - val_accuracy: 0.8852 - val_loss: 0.3071\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 365ms/step - accuracy: 0.9185 - loss: 0.2382 - val_accuracy: 0.8870 - val_loss: 0.3175\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 366ms/step - accuracy: 0.9307 - loss: 0.2104 - val_accuracy: 0.8594 - val_loss: 0.3349\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 364ms/step - accuracy: 0.9362 - loss: 0.2005 - val_accuracy: 0.8838 - val_loss: 0.3812\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 365ms/step - accuracy: 0.9484 - loss: 0.1626 - val_accuracy: 0.8818 - val_loss: 0.3438\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 366ms/step - accuracy: 0.9543 - loss: 0.1468 - val_accuracy: 0.8806 - val_loss: 0.4055\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 364ms/step - accuracy: 0.9598 - loss: 0.1327 - val_accuracy: 0.8750 - val_loss: 0.4409\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc5ec071410>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Lambda(\n",
        "    lambda x : tf.one_hot(x, depth = max_tokens),\n",
        "    output_shape = lambda s : (s[0], s[1], max_tokens) )(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    int_train_ds.cache(),\n",
        "    validation_data = int_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbTKdwQc-tkL"
      },
      "source": [
        "이 모델의 훈련은 입력크기가 매우 크기때문에 (샘플당 600개의 단어가 있고 각 단어는 2만 개의 단어 중 하나), 훈련이 매우 느림\n",
        "\n",
        "또한, 테스트 정확도가 좋지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "PS8FPRD79qiO",
        "outputId": "6508c571-f403-41df-ae49-9d978d210828"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mname 'max_tokens' is not defined\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, None), dtype=int64, sparse=False, name=input_layer>',)\n  • kwargs={'mask': 'None'}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-716510d0eb7e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_hot_bidir_lstm.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    363\u001b[0m             )\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    494\u001b[0m                     \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0;31m# If the node does not have all inbound layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# Call layer on its inputs, thus creating the node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# and building the layer if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/python_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      3\u001b[0m embedded = layers.Lambda(\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     output_shape = lambda s : (s[0], s[1], max_tokens) )(inputs)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mname 'max_tokens' is not defined\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, None), dtype=int64, sparse=False, name=input_layer>',)\n  • kwargs={'mask': 'None'}"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\", safe_mode = False)\n",
        "print(f\"테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM_slOUcFKBo"
      },
      "source": [
        "## 단어 임베딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EaXYiAJFHRV"
      },
      "source": [
        "### 단어 임베딩을 만드는 첫번째 방법 - Embedding 층으로 단어 임베딩 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_TsmlI99Z5N"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    input_dim = max_tokens,\n",
        "    output_dim = 256\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "FlHNClkXeerr",
        "outputId": "cc3dbd0e-b71d-4a47-f108-e327bdd922c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m73,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.6082 - loss: 0.6389 - val_accuracy: 0.8286 - val_loss: 0.4178\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.8228 - loss: 0.4400 - val_accuracy: 0.8044 - val_loss: 0.4198\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.8681 - loss: 0.3456 - val_accuracy: 0.8674 - val_loss: 0.3336\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39ms/step - accuracy: 0.8895 - loss: 0.3017 - val_accuracy: 0.8662 - val_loss: 0.3591\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9155 - loss: 0.2505 - val_accuracy: 0.8754 - val_loss: 0.3585\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - accuracy: 0.9241 - loss: 0.2212 - val_accuracy: 0.8706 - val_loss: 0.3618\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9394 - loss: 0.1962 - val_accuracy: 0.8772 - val_loss: 0.3645\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.9488 - loss: 0.1607 - val_accuracy: 0.8780 - val_loss: 0.4115\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9569 - loss: 0.1361 - val_accuracy: 0.8724 - val_loss: 0.4240\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9665 - loss: 0.1190 - val_accuracy: 0.8758 - val_loss: 0.4865\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc5ed22f110>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = keras.Input(shape = (None,), dtype = 'int64')\n",
        "embedded = layers.Embedding(\n",
        "    input_dim = max_tokens,\n",
        "    output_dim = 256\n",
        ")(inputs)\n",
        "\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    int_train_ds.cache(),\n",
        "    validation_data = int_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wMXNZhjfHDx",
        "outputId": "f0608e54-e925-4df2-f9af-e54dd819efc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8456 - loss: 0.3676\n",
            "테스트 정확도  : 0.847\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"embeddings_bidir_lstm.keras\")\n",
        "print(f\"테스트 정확도  : {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5To4sWLfPrz"
      },
      "source": [
        "이제 LSTM이 20000차원이 아니라 256차원 벡터를 처리하기 때문에 이 모델은 원-핫 모델보다 훨씬 빠르고 테스트 정확도는 비슷함  \n",
        "하지만 여전히 기본적인 바이그램 모델의 결과보다 차이가 남. 이유 중 하나는 이 모델이 약간 적은 데이터를 사용하기 때문임. 바이그램 모델은 전체 리뷰를 처리하지만, 이 시퀀스 모델은 600개의 단어 이후 시퀀스는 잘라 버리기 때문"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7UN8Jtg7QY"
      },
      "source": [
        "### 패딩과 마스킹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfTxTKZAfV0H"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    input_dim = 10,\n",
        "    output_dim = 256,\n",
        "    mask_zero = True\n",
        ")\n",
        "\n",
        "some_input = [\n",
        "    [4, 3, 2, 1, 0, 0, 0],\n",
        "    [5, 4, 3, 2, 1, 0, 0],\n",
        "    [2, 1, 0, 0, 0, 0, 0]\n",
        "]\n",
        "\n",
        "mask = embedding_layer.compute_mask(some_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "Z917Z6hehUzK",
        "outputId": "b8ea3d34-a472-4dce-df86-f20e6a11aad3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,120,000\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m73,984\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,194,049</span> (19.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,194,049\u001b[0m (19.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.6746 - loss: 0.5814 - val_accuracy: 0.8622 - val_loss: 0.3367\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - accuracy: 0.8618 - loss: 0.3309 - val_accuracy: 0.8774 - val_loss: 0.2936\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 41ms/step - accuracy: 0.9001 - loss: 0.2541 - val_accuracy: 0.8494 - val_loss: 0.4023\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9226 - loss: 0.2061 - val_accuracy: 0.8278 - val_loss: 0.4979\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.9409 - loss: 0.1586 - val_accuracy: 0.8690 - val_loss: 0.3856\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.9605 - loss: 0.1172 - val_accuracy: 0.8754 - val_loss: 0.4246\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9668 - loss: 0.0907 - val_accuracy: 0.8722 - val_loss: 0.3853\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9781 - loss: 0.0661 - val_accuracy: 0.8812 - val_loss: 0.4360\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - accuracy: 0.9862 - loss: 0.0449 - val_accuracy: 0.8760 - val_loss: 0.5341\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9894 - loss: 0.0336 - val_accuracy: 0.8782 - val_loss: 0.6024\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bc5ec322310>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = keras.Input(shape = (None,), dtype = 'int64')\n",
        "embedded = layers.Embedding(\n",
        "    input_dim = max_tokens, output_dim = 256, mask_zero = True)(inputs)\n",
        "\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm_with_masking.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    int_train_ds.cache(),\n",
        "    validation_data = int_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWrk4sJIiqKB"
      },
      "source": [
        "## 단어 임베딩을 만드는 두번째 방법 - 사전 훈련된 단어 임베딩 사용하기\n",
        "\n",
        "GloVec 임베딩을 케라스 모델에서 어떻게 사용하는지 알아보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYi6Z9ySkIsd"
      },
      "source": [
        "먼저 GloVec 파일을 내려받고 파싱해야 함.  \n",
        "그 후 단어 벡터를 케라스 Embedding 층으로 로드하여 새로운 모델을 만들어 보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6G8ZZeQiufP",
        "outputId": "72fa3e8f-042f-4492-e170-8ef0ec5df470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-23 12:44:54--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-01-23 12:44:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-01-23 12:44:55--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.99MB/s    in 2m 39s  \n",
            "\n",
            "2025-01-23 12:47:35 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJl5Shpnkj-u",
        "outputId": "408d70db-4bfe-46f3-ab3b-0b8cd16ec737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 벡터 개수 : 400000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "path_to_glove_file = 'glove.6B.100d.txt' # embedding_dim이 100이다.\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coef = line.split(maxsplit = 1)\n",
        "    coefs = np.fromstring(coef, \"f\", sep = \" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"단어 벡터 개수 : {len(embeddings_index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (word, wordvec) in enumerate(embeddings_index.items()):\n",
        "  print(word, wordvec)\n",
        "  if i >= 2:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4optEdfVNqDO",
        "outputId": "26ac8bb4-9d86-4128-add2-c1128c4c06fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            ", [-0.10767    0.11053    0.59812   -0.54361    0.67396    0.10663\n",
            "  0.038867   0.35481    0.06351   -0.094189   0.15786   -0.81665\n",
            "  0.14172    0.21939    0.58505   -0.52158    0.22783   -0.16642\n",
            " -0.68228    0.3587     0.42568    0.19021    0.91963    0.57555\n",
            "  0.46185    0.42363   -0.095399  -0.42749   -0.16567   -0.056842\n",
            " -0.29595    0.26037   -0.26606   -0.070404  -0.27662    0.15821\n",
            "  0.69825    0.43081    0.27952   -0.45437   -0.33801   -0.58184\n",
            "  0.22364   -0.5778    -0.26862   -0.20425    0.56394   -0.58524\n",
            " -0.14365   -0.64218    0.0054697 -0.35248    0.16162    1.1796\n",
            " -0.47674   -2.7553    -0.1321    -0.047729   1.0655     1.1034\n",
            " -0.2208     0.18669    0.13177    0.15117    0.7131    -0.35215\n",
            "  0.91348    0.61783    0.70992    0.23955   -0.14571   -0.37859\n",
            " -0.045959  -0.47368    0.2385     0.20536   -0.18996    0.32507\n",
            " -1.1112    -0.36341    0.98679   -0.084776  -0.54008    0.11726\n",
            " -1.0194    -0.24424    0.12771    0.013884   0.080374  -0.35414\n",
            "  0.34951   -0.7226     0.37549    0.4441    -0.99059    0.61214\n",
            " -0.35111   -0.83155    0.45293    0.082577 ]\n",
            ". [-0.33979    0.20941    0.46348   -0.64792   -0.38377    0.038034\n",
            "  0.17127    0.15978    0.46619   -0.019169   0.41479   -0.34349\n",
            "  0.26872    0.04464    0.42131   -0.41032    0.15459    0.022239\n",
            " -0.64653    0.25256    0.043136  -0.19445    0.46516    0.45651\n",
            "  0.68588    0.091295   0.21875   -0.70351    0.16785   -0.35079\n",
            " -0.12634    0.66384   -0.2582     0.036542  -0.13605    0.40253\n",
            "  0.14289    0.38132   -0.12283   -0.45886   -0.25282   -0.30432\n",
            " -0.11215   -0.26182   -0.22482   -0.44554    0.2991    -0.85612\n",
            " -0.14503   -0.49086    0.0082973 -0.17491    0.27524    1.4401\n",
            " -0.21239   -2.8435    -0.27958   -0.45722    1.6386     0.78808\n",
            " -0.55262    0.65       0.086426   0.39012    1.0632    -0.35379\n",
            "  0.48328    0.346      0.84174    0.098707  -0.24213   -0.27053\n",
            "  0.045287  -0.40147    0.11395    0.0062226  0.036673   0.018518\n",
            " -1.0213    -0.20806    0.64072   -0.068763  -0.58635    0.33476\n",
            " -1.1432    -0.1148    -0.25091   -0.45907   -0.096819  -0.17946\n",
            " -0.063351  -0.67412   -0.068895   0.53604   -0.87773    0.31802\n",
            " -0.39242   -0.23394    0.47298   -0.028803 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XNVCH_2hnIJG"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary() # TextVectorization층에 인덱싱된 단어를 추출(즉, 우리의 testdataset에 있던)\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "word_index\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 Constant 초기화를 사용하여 Embedding 층에 사전 훈련된 임베딩을 로드함.  \n",
        "훈련하는 동안 사전 훈련된 표현이 변경되지 않도록 trainable=False로 이 층을 동결함."
      ],
      "metadata": {
        "id": "qunT8HiEMtC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J9S9CdOZnYnm"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer = keras.initializers.Constant(embedding_matrix),\n",
        "    trainable = False,\n",
        "    mask_zero = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyjZPm-PqhHw"
      },
      "source": [
        "이제 100차원의 사전 훈련된 GloVe 임베딩을 사용해 보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "A57lscLgqh0k",
        "outputId": "9e9cb39c-5388-4bb3-eeb3-fd57d68ce297"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m2,000,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m34,048\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34,048</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,034,113\u001b[0m (7.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,034,113</span> (7.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,113\u001b[0m (133.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,113</span> (133.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 54ms/step - accuracy: 0.6201 - loss: 0.6388 - val_accuracy: 0.7630 - val_loss: 0.4890\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 44ms/step - accuracy: 0.7805 - loss: 0.4728 - val_accuracy: 0.8094 - val_loss: 0.4133\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 49ms/step - accuracy: 0.8154 - loss: 0.4178 - val_accuracy: 0.8294 - val_loss: 0.3816\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.8375 - loss: 0.3824 - val_accuracy: 0.8202 - val_loss: 0.3895\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - accuracy: 0.8518 - loss: 0.3535 - val_accuracy: 0.8106 - val_loss: 0.4345\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.8651 - loss: 0.3310 - val_accuracy: 0.8524 - val_loss: 0.3579\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - accuracy: 0.8745 - loss: 0.3134 - val_accuracy: 0.8580 - val_loss: 0.3576\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 44ms/step - accuracy: 0.8845 - loss: 0.2937 - val_accuracy: 0.8682 - val_loss: 0.3261\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.8892 - loss: 0.2796 - val_accuracy: 0.8630 - val_loss: 0.3692\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - accuracy: 0.8968 - loss: 0.2676 - val_accuracy: 0.8662 - val_loss: 0.3494\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a3d9a705090>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "inputs = keras.Input(shape = (None,), dtype = 'int64')\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_bidir_sequence_model.keras\",\n",
        "                                    save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    int_train_ds.cache(),\n",
        "    validation_data = int_val_ds.cache(),\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"glove_embeddings_bidir_sequence_model.keras\")\n",
        "print(f\"테스트 정확도  : {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsTsqtJkTS7W",
        "outputId": "ae33a20d-a8a1-4707-dd15-b98f5ececee6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.8657 - loss: 0.3298\n",
            "테스트 정확도  : 0.861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 작업에서는 사전 훈련된 임베딩이 별로 도움이 되지는 않는 것 같음. 작업에 특화된 임베딩 공간을 밑바닥부터 학습하기에 충분한 샘플이 데이터셋에 있기 때문.  \n",
        "하지만 작은 데이터셋을 다룰 때는 사전 훈련된 임베딩을 사용하면 크게 도움이 될 수 있음.\n"
      ],
      "metadata": {
        "id": "Qyc5_ZBLQcr7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNtkpnkIWCz8mBjGKVPGS6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}