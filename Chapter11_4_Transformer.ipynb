{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNve9XV0wufneB8jRWQq1As",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hws2002/Deep_Learning_with_Keras/blob/main/Chapter11_4_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR601cclQsCW"
      },
      "outputs": [],
      "source": [
        "def self_attention(input_sequence):\n",
        "  output = np.zeros(shape = input_sequence.shape)\n",
        "  for i, pivot_vector in enumerate(input_sequence):\n",
        "    scores = np.zeros(shape = (len(input_sequence),))\n",
        "    for j, vector in enumerate(input_sequence):\n",
        "      scores[j] = np.dot(pivot_vector, vector.T)\n",
        "    scores /= np.sqrt(input_sequence.shape[1])\n",
        "    scores = softmax(scores)\n",
        "    new_pivot_representation = np.zeros(shape = pivot_vector.shape)\n",
        "\n",
        "    for j, vector in enumerate(input_sequence):\n",
        "        new_pivot_representation += vector * scores[j]\n",
        "    output[i] = new_pivot_representation\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 4\n",
        "embed_dim = 256\n",
        "\n",
        "mha_layer = MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
        "outputs = mha_layer(inputs, inputs, inputs)"
      ],
      "metadata": {
        "id": "J8UzghCtx90C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Layer 층을 상속하여 구현한 트랜스포머 인코디"
      ],
      "metadata": {
        "id": "zzsDbMEr36QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSa3H73y4HhS",
        "outputId": "7d719096-6444-4d84-daaf-458521b505f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb': No such file or directory\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  35.0M      0  0:00:02  0:00:02 --:--:-- 35.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = os.path.join(\"aclImdb\")\n",
        "\n",
        "base_dir = 'aclImdb'\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test/'\n",
        "\n",
        "train_dataset = []\n",
        "val_dataset = [] # 20%만 떼어가자\n",
        "\n",
        "train_pos_path = os.path.join(base_path, train_dir, 'pos')\n",
        "train_neg_path = os.path.join(base_path, train_dir, 'neg')\n",
        "\n",
        "train_pos_listdir = os.listdir(train_pos_path)\n",
        "num_val_pos_data = int(0.2 * len(train_pos_listdir))\n",
        "train_neg_listdir = os.listdir(train_neg_path)\n",
        "num_val_neg_data = int(0.2 * len(train_neg_listdir))\n",
        "\n",
        "for filename in train_pos_listdir[:-num_val_pos_data]:\n",
        "  with open(os.path.join(train_pos_path,filename),'r') as f:\n",
        "    train_dataset.append(f.read())\n",
        "for filename in train_pos_listdir[-num_val_pos_data:]:\n",
        "  with open(os.path.join(train_pos_path,filename),'r') as f:\n",
        "    val_dataset.append(f.read())\n",
        "\n",
        "num_train_pos_data = len(train_dataset)\n",
        "\n",
        "for filename in train_neg_listdir[:-num_val_neg_data]:\n",
        "  with open(os.path.join(train_neg_path,filename),'r') as f:\n",
        "    train_dataset.append(f.read())\n",
        "\n",
        "for filename in train_neg_listdir[-num_val_neg_data:]:\n",
        "  with open(os.path.join(train_neg_path,filename),'r') as f:\n",
        "    val_dataset.append(f.read())\n",
        "num_train_neg_data = len(train_dataset) - num_train_pos_data\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkULqrKw4H6i",
        "outputId": "d8adf1b9-04c4-4040-fbd9-981e2bf57ed6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / 'val'\n",
        "train_dir = base_dir / 'train'\n",
        "\n",
        "for category in (\"neg\",\"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int( 0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname ,\n",
        "                val_dir / category / fname)"
      ],
      "metadata": {
        "id": "LFKM0To24NO6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/val', batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test', batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SaNTE3f4Opz",
        "outputId": "deb3a029-0743-4d9a-b385-4716fdc0847b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.embed_dim = embed_dim # 입력 토큰 벡터의 크기\n",
        "    self.dense_dim = dense_dim # 내부 밀집 층의 크기\n",
        "    self.num_heads = num_heads # 어텐션 헤드의 크기\n",
        "    self.attention = layers.MultiHeadAttention(\n",
        "        num_heads = num_heads,\n",
        "        key_dim = embed_dim,\n",
        "    )\n",
        "    self.dense_proj = keras.Sequential(\n",
        "        [layers.Dense(dense_dim, activation = \"relu\"),\n",
        "         layers.Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1 = layers.LayerNormalization()\n",
        "    self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "  def call(self, inputs, mask = None): # call() 메서드에서 연산을 수행함\n",
        "    if mask is not None:\n",
        "      mask = mask[:, tf.newaxis, :]  # Embedding 층에서 생성하는 마스크는 2D이지만, 어텐션 층은 3D 또는 4D를 기대하므로\n",
        "    attention_output = self.attention(inputs, inputs, attention_mask = mask) # 랭크를 늘림\n",
        "    proj_input = self.layernorm_1(layers.add([attention_output, inputs]))\n",
        "    proj_output = self.dense_proj(proj_input)\n",
        "    return self.layernorm_2(layers.add([proj_output, proj_input]))\n",
        "\n",
        "  def get_config(self): # 모델을 저장할 수 있도록 직렬화를 구현\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "        \"embed_dim\" : self.embed_dim,\n",
        "        \"num_heads\" : self.num_heads,\n",
        "        \"dense_dim\" : self.dense_dim,\n",
        "    })\n",
        "    return config"
      ],
      "metadata": {
        "id": "wsulQZlE39No"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/val', batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test', batch_size = batch_size\n",
        ")\n",
        "\n",
        "text_only_train_ds = train_ds.map(lambda x, y : x)\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens = max_tokens,\n",
        "    output_mode = \"int\",\n",
        "    output_sequence_length = max_length, # 적당한 입력 크기를 유지하기 위해 입력에서 600개 단어 이후는 잘라 버림\n",
        "    # 평균 리뷰 길이가 233개의 단어고 600개의 단어보다 긴 리뷰는 5%뿐이므로 합리적인 선택임.\n",
        ")\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)\n",
        "\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)\n",
        "\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls = 4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5AFtgLwo7b",
        "outputId": "acc9c44b-bff6-4a1d-a50a-b9663cd7289b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 TransformerEncoder를 구현했으므로 이를 사용하여 LSTM 기반 모델과 비슷한 텍스트 분류 모델을 만들어 보자."
      ],
      "metadata": {
        "id": "x1t4r5h4sGRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape = (None,), dtype = \"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x) # TransformerEncoder가 전체 시퀀스를 반환하기 때문에\n",
        "# 분류 작업을 위해 전역 풀링 층으로 각 시퀀스를 하나의 벡터로 만든다.\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer = \"rmsprop\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZG667LACldGs",
        "outputId": "32113276-ce60-421b-dd7a-3091e71a0262"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m543,776\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 훈련해보자  \n"
      ],
      "metadata": {
        "id": "5mfzylxrwJna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"transformer_encoder.keras\",\n",
        "        save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(int_train_ds, validation_data = int_val_ds, epochs = 20,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder.keras\",\n",
        "    custom_objects = {\n",
        "        \"TransformerEncoder\" : TransformerEncoder\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fna0GrUcvn6m",
        "outputId": "7c32d914-dd98-47d6-b0f2-645f9e78e097"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 98ms/step - accuracy: 0.5392 - loss: 0.8714 - val_accuracy: 0.8292 - val_loss: 0.3904\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 93ms/step - accuracy: 0.8128 - loss: 0.4104 - val_accuracy: 0.8462 - val_loss: 0.3562\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.8467 - loss: 0.3532 - val_accuracy: 0.8610 - val_loss: 0.3210\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.8641 - loss: 0.3226 - val_accuracy: 0.8690 - val_loss: 0.3168\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 94ms/step - accuracy: 0.8732 - loss: 0.3005 - val_accuracy: 0.8710 - val_loss: 0.3083\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 95ms/step - accuracy: 0.8849 - loss: 0.2737 - val_accuracy: 0.8632 - val_loss: 0.3320\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 95ms/step - accuracy: 0.8951 - loss: 0.2538 - val_accuracy: 0.8696 - val_loss: 0.3047\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 95ms/step - accuracy: 0.8991 - loss: 0.2414 - val_accuracy: 0.8782 - val_loss: 0.2908\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - accuracy: 0.9119 - loss: 0.2173 - val_accuracy: 0.8770 - val_loss: 0.2899\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 97ms/step - accuracy: 0.9206 - loss: 0.1982 - val_accuracy: 0.8710 - val_loss: 0.3167\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 103ms/step - accuracy: 0.9325 - loss: 0.1759 - val_accuracy: 0.8760 - val_loss: 0.3165\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 96ms/step - accuracy: 0.9393 - loss: 0.1580 - val_accuracy: 0.8732 - val_loss: 0.3411\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 96ms/step - accuracy: 0.9442 - loss: 0.1413 - val_accuracy: 0.8754 - val_loss: 0.3358\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 96ms/step - accuracy: 0.9551 - loss: 0.1227 - val_accuracy: 0.8680 - val_loss: 0.3747\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 92ms/step - accuracy: 0.9573 - loss: 0.1145 - val_accuracy: 0.8650 - val_loss: 0.3962\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 94ms/step - accuracy: 0.9621 - loss: 0.1007 - val_accuracy: 0.8722 - val_loss: 0.4063\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 92ms/step - accuracy: 0.9660 - loss: 0.0939 - val_accuracy: 0.8722 - val_loss: 0.4123\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 88ms/step - accuracy: 0.9691 - loss: 0.0829 - val_accuracy: 0.8726 - val_loss: 0.3946\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 84ms/step - accuracy: 0.9763 - loss: 0.0728 - val_accuracy: 0.8732 - val_loss: 0.4249\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - accuracy: 0.9799 - loss: 0.0580 - val_accuracy: 0.8696 - val_loss: 0.4380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90f_NVOXwxKD",
        "outputId": "b7250733-9d34-4fa9-96b7-e79f55f6d13d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.8716 - loss: 0.3078\n",
            "테스트 정확도 : 0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 위치 인코딩을 사용해서 위치 정보 주입하기"
      ],
      "metadata": {
        "id": "ueaH2tVczrUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]  # Get the batch size\n",
        "        length = tf.shape(inputs)[-1]  # Get the sequence length\n",
        "\n",
        "        # Create the positions tensor for the sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "\n",
        "        # Expand dimensions to match batch size\n",
        "        positions = tf.expand_dims(positions, 0)  # Add a batch dimension\n",
        "        positions = tf.tile(positions, [batch_size, 1])  # Repeat positions for each sample in the batch\n",
        "\n",
        "        # Get embeddings for tokens and positions\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Return the mask for padding (0)\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "KgApvNenxHb4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 분류 트랜스포머"
      ],
      "metadata": {
        "id": "XMq-ozOw2pTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape = (None,), dtype = \"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x) # TransformerEncoder가 전체 시퀀스를 반환하기 때문에\n",
        "# 분류 작업을 위해 전역 풀링 층으로 각 시퀀스를 하나의 벡터로 만든다.\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer = \"rmsprop\",\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "82Vxkr0e2HbI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "mudhZ_EC4TjS",
        "outputId": "eb1b6ed5-934b-4e12-eb4b-eb87973e38c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m543,776\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,328,068\u001b[0m (43.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,328,068</span> (43.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,664,035\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,035</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"full_transformer_encoder.keras\",\n",
        "        save_best_only = True)\n",
        "]\n",
        "\n",
        "model.fit(int_train_ds, validation_data = int_val_ds, epochs = 20,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder.keras\",\n",
        "    custom_objects = {\n",
        "        \"TransformerEncoder\" : TransformerEncoder,\n",
        "        \"PositionalEmbedding\" : PositionalEmbedding\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUoavWgN25fc",
        "outputId": "c23d34c1-78d8-4806-d50d-e8b1b84b798d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 97ms/step - accuracy: 0.9257 - loss: 0.1888 - val_accuracy: 0.8736 - val_loss: 0.3094\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 97ms/step - accuracy: 0.9334 - loss: 0.1728 - val_accuracy: 0.8756 - val_loss: 0.3387\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 95ms/step - accuracy: 0.9412 - loss: 0.1559 - val_accuracy: 0.8740 - val_loss: 0.3569\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - accuracy: 0.9474 - loss: 0.1391 - val_accuracy: 0.8722 - val_loss: 0.3406\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 93ms/step - accuracy: 0.9566 - loss: 0.1204 - val_accuracy: 0.8684 - val_loss: 0.3717\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.9617 - loss: 0.1069 - val_accuracy: 0.8710 - val_loss: 0.3962\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 90ms/step - accuracy: 0.9652 - loss: 0.0969 - val_accuracy: 0.8668 - val_loss: 0.4086\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 88ms/step - accuracy: 0.9729 - loss: 0.0777 - val_accuracy: 0.8642 - val_loss: 0.4562\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 86ms/step - accuracy: 0.9752 - loss: 0.0688 - val_accuracy: 0.8550 - val_loss: 0.5098\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 84ms/step - accuracy: 0.9800 - loss: 0.0570 - val_accuracy: 0.8648 - val_loss: 0.5333\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 83ms/step - accuracy: 0.9848 - loss: 0.0454 - val_accuracy: 0.8604 - val_loss: 0.5780\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - accuracy: 0.9859 - loss: 0.0413 - val_accuracy: 0.8562 - val_loss: 0.5593\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 77ms/step - accuracy: 0.9868 - loss: 0.0378 - val_accuracy: 0.8582 - val_loss: 0.6086\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 75ms/step - accuracy: 0.9900 - loss: 0.0295 - val_accuracy: 0.8596 - val_loss: 0.7273\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 70ms/step - accuracy: 0.9915 - loss: 0.0236 - val_accuracy: 0.8562 - val_loss: 0.6393\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 69ms/step - accuracy: 0.9936 - loss: 0.0182 - val_accuracy: 0.8460 - val_loss: 0.7582\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.9937 - loss: 0.0174 - val_accuracy: 0.8582 - val_loss: 0.7707\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.8558 - val_loss: 0.8381\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9946 - loss: 0.0142 - val_accuracy: 0.8582 - val_loss: 0.8526\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.8600 - val_loss: 0.8245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4MfRBGq43lC",
        "outputId": "4c26a2c5-915b-4b08-e7ac-39b3039a5054"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8598 - loss: 0.3395\n",
            "테스트 정확도 : 0.861\n"
          ]
        }
      ]
    }
  ]
}